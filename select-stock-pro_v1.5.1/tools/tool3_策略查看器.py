# -*- coding: utf-8 -*-
"""
é‚¢ä¸è¡Œï½œç­–ç•¥åˆ†äº«ä¼š
è‚¡ç¥¨é‡åŒ–ç­–ç•¥æ¡†æ¶ğ“Ÿğ“»ğ“¸

ç‰ˆæƒæ‰€æœ‰ Â©ï¸ é‚¢ä¸è¡Œ
å¾®ä¿¡: xbx1717

æœ¬ä»£ç ä»…ä¾›ä¸ªäººå­¦ä¹ ä½¿ç”¨ï¼Œæœªç»æˆæƒä¸å¾—å¤åˆ¶ã€ä¿®æ”¹æˆ–ç”¨äºå•†ä¸šç”¨é€”ã€‚

Author: é‚¢ä¸è¡Œ
"""

import numpy as np
import pandas as pd
from pathlib import Path
import tools.utils.tfunctions as tf
import tools.utils.pfunctions as pf
from core.model.backtest_config import load_config
import os
import warnings
from urllib.parse import quote

warnings.filterwarnings("ignore")


# region ===== è¾…åŠ©å‡½æ•° =====
# è¯»å–é€‰è‚¡ç»“æœæ•°æ®
def load_select_data(_strategy_name, _start_time, _end_time, _results_dir) -> pd.DataFrame:
    """åŠ è½½ç­–ç•¥é€‰è‚¡ç»“æœ"""
    file_path = os.path.join(_results_dir, f"é€‰è‚¡ç»“æœ.pkl")
    temp = pd.read_pickle(file_path)
    if temp.empty:
        raise ValueError(f"{_strategy_name} é€‰è‚¡ç»“æœæ–‡ä»¶ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®")
    df = temp[temp["ç­–ç•¥"] == _strategy_name]
    # ç±»å‹è½¬æ¢
    str_cols = ["è‚¡ç¥¨ä»£ç ", "è‚¡ç¥¨åç§°", "ç­–ç•¥", "æŒä»“å‘¨æœŸ", "æ¢ä»“æ—¶é—´"]
    df[str_cols] = df[str_cols].astype(str)
    # æ—¶é—´è¿‡æ»¤
    df = df[(df["é€‰è‚¡æ—¥æœŸ"] >= pd.to_datetime(_start_time)) & (df["é€‰è‚¡æ—¥æœŸ"] <= pd.to_datetime(_end_time))]
    if df.empty:
        raise ValueError(f"å›æµ‹æ—¶é—´å’Œåˆ†ææ—¶é—´æ²¡æœ‰äº¤é›†ï¼Œè¯·æ£€æŸ¥æ•°æ®")
    return df


# è¯»å–kçº¿æ•°æ®
def load_kline_data(_stocks, _all_add_factor, _cache_dir) -> pd.DataFrame:
    all_factors_kline = pd.read_pickle(os.path.join(_cache_dir, "all_factors_kline.pkl"))
    if all_factors_kline.empty:
        raise ValueError("å›æµ‹æ–‡ä»¶å¤¹ä¸‹ all_factors_kline æ–‡ä»¶æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®")
    all_factors_kline = all_factors_kline[["äº¤æ˜“æ—¥æœŸ", "è‚¡ç¥¨ä»£ç "]]

    # è¯»å–æ‰€éœ€å› å­ä¿¡æ¯
    factors_pkl = [_dir[7:-4] for _dir in os.listdir(_cache_dir) if _dir.startswith("factor_")]
    for factor_name in _all_add_factor:
        if factor_name not in factors_pkl + ["æŒ‡æ•°"]:
            raise ValueError(f"{factor_name} å› å­ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥æ•°æ®")
        if factor_name in factors_pkl:
            factor = pd.read_pickle(os.path.join(_cache_dir, f"factor_{factor_name}.pkl"))
            if factor.empty:
                raise ValueError(f"{factor} å› å­æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®")
            if len(all_factors_kline) != len(factor):
                raise ValueError(f"{factor} å› å­é•¿åº¦ä¸åŒ¹é…ï¼Œéœ€è¦é‡æ–°å›æµ‹ï¼Œæ›´æ–°æ•°æ®")
            all_factors_kline[factor_name] = factor

    # åªä¿ç•™æ‰€éœ€è‚¡ç¥¨çš„æ•°æ®
    all_factors_kline = all_factors_kline[all_factors_kline["è‚¡ç¥¨ä»£ç "].isin(_stocks)]
    # è°ƒæ•´æ•°æ®æ ¼å¼
    all_factors_kline[["è‚¡ç¥¨ä»£ç "]] = all_factors_kline[["è‚¡ç¥¨ä»£ç "]].astype(str)
    all_factors_kline = all_factors_kline.sort_values(by=["è‚¡ç¥¨ä»£ç ", "äº¤æ˜“æ—¥æœŸ"])

    # è¯»å–å…¨éƒ¨çš„è‚¡ç¥¨è¡Œæƒ…æ•°æ®
    stocks_data_dict = pd.read_pickle(os.path.join(_cache_dir, "è‚¡ç¥¨é¢„å¤„ç†æ•°æ®.pkl"))
    if not stocks_data_dict:
        raise ValueError("å›æµ‹æ–‡ä»¶å¤¹ä¸‹ è‚¡ç¥¨é¢„å¤„ç†æ•°æ® æ–‡ä»¶æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®")
    all_data = pd.concat(stocks_data_dict.values())
    del stocks_data_dict
    # ä¸å› å­æ•°æ®åˆå¹¶
    all_factors_kline = pd.merge(all_factors_kline, all_data, on=["äº¤æ˜“æ—¥æœŸ", "è‚¡ç¥¨ä»£ç "], how="left")
    return all_factors_kline


# åˆå§‹åŒ–ç›®å½•
def init_directories(_strategy_name, _backtest_name, _start_time, _end_time, _analysis_dir) -> tuple:
    """åˆå§‹åŒ–ç»“æœä¿å­˜ç›®å½•"""
    _save_path = os.path.join(
        _analysis_dir, f"{_backtest_name}/{str(_strategy_name).replace('#', '')}_{_start_time}_{_end_time}/"
    )
    _fig_save_path = os.path.join(_save_path, "é€‰è‚¡è¡Œæƒ…å›¾/")
    os.makedirs(_save_path, exist_ok=True)
    os.makedirs(_fig_save_path, exist_ok=True)
    return _save_path, _fig_save_path


# offsetæ•°æ®
def merge_period_offset(_select: pd.DataFrame, _period_offset_df: pd.DataFrame) -> pd.DataFrame:
    result_df = pd.DataFrame()
    for period_offset in _select["æŒä»“å‘¨æœŸ"].unique():
        _sing_period_offset_select = _select[_select["æŒä»“å‘¨æœŸ"] == period_offset].copy()
        # offsetä¿¡æ¯
        result_df_temp = _period_offset_df[["äº¤æ˜“æ—¥æœŸ"]].copy()
        result_df_temp["æŒæœ‰å¼€å§‹"] = _period_offset_df["äº¤æ˜“æ—¥æœŸ"].copy()
        result_df_temp["æŒæœ‰åˆ°æœŸ"] = _period_offset_df["äº¤æ˜“æ—¥æœŸ"].copy()
        result_df_temp["_group"] = _period_offset_df[period_offset].copy()
        result_df_temp.loc[result_df_temp["_group"] < 0, "æŒæœ‰åˆ°æœŸ"] = None
        result_df_temp[f"æŒæœ‰å¤©æ•°"] = 1
        result_df_temp.loc[result_df_temp["_group"] < 0, "æŒæœ‰å¤©æ•°"] = 0
        result_df_temp["group"] = result_df_temp["_group"].abs()

        po_df = (
            result_df_temp.groupby([f"group"])
            .agg({"æŒæœ‰å¼€å§‹": "first", "æŒæœ‰åˆ°æœŸ": "last", "äº¤æ˜“æ—¥æœŸ": "last", "æŒæœ‰å¤©æ•°": "sum"})
            .reset_index()
        )
        po_df["æŒæœ‰å‘¨æœŸ"] = po_df["æŒæœ‰å¼€å§‹"].dt.date.apply(str) + "--" + po_df["æŒæœ‰åˆ°æœŸ"].dt.date.apply(str)

        po_df["æŒæœ‰å¼€å§‹"] = po_df["æŒæœ‰å¼€å§‹"].shift(-1)
        po_df["æŒæœ‰åˆ°æœŸ"] = po_df["æŒæœ‰åˆ°æœŸ"].shift(-1)
        po_df["æŒæœ‰å‘¨æœŸ"] = po_df["æŒæœ‰å‘¨æœŸ"].shift(-1)
        po_df["æŒæœ‰å¤©æ•°"] = po_df["æŒæœ‰å¤©æ•°"].shift(-1)
        po_df.rename(columns={"äº¤æ˜“æ—¥æœŸ": "é€‰è‚¡æ—¥æœŸ"}, inplace=True)
        _sing_period_offset_select = pd.merge(
            _sing_period_offset_select,
            po_df[["é€‰è‚¡æ—¥æœŸ", "æŒæœ‰å¼€å§‹", "æŒæœ‰åˆ°æœŸ", "æŒæœ‰å‘¨æœŸ", "æŒæœ‰å¤©æ•°"]],
            on="é€‰è‚¡æ—¥æœŸ",
            how="left",
        )
        result_df = pd.concat([result_df, _sing_period_offset_select], ignore_index=True)
    return result_df


# è®¡ç®—å¤æƒä»·æ ¼
def calculate_adjusted_prices(price_df: pd.DataFrame, _rebalanced_time: str) -> pd.DataFrame:
    """
    è®¡ç®—å¤æƒä»·æ ¼
    """
    # è®¡ç®—åˆ†é’Ÿä»·æ ¼çš„å¤æƒä»·æ ¼
    if _rebalanced_time not in ["close-open", "close", "open"]:
        _rebalanced_time_5min = _rebalanced_time.split("-")[0]
        price_df[f"{_rebalanced_time_5min}_å¤æƒ"] = (
            price_df[_rebalanced_time_5min] / price_df["æ”¶ç›˜ä»·"] * price_df["æ”¶ç›˜ä»·_å¤æƒ"]
        )
    else:
        return price_df
    # å¯¹äº close-open / open / close ä¸‰ç§æ¨¡å¼ï¼Œç›´æ¥è¿”å›æ•°æ®
    return price_df


# è®¡ç®—æŒæœ‰æœŸé—´çš„æ”¶ç›Šç‡
def get_buy_sell_ret(_all_factors_kline, _select, _rebalanced_time, _c_rate, _t_rate):
    """
    ç”¨å¤æƒä»·æ ¼è®¡ç®—è‚¡ç¥¨æŒä»“æ—¶é—´å†…çš„æ•´ä½“æ”¶ç›Šç‡
    """
    # é¢„å¤„ç†æ•°æ®ï¼Œç”Ÿæˆéœ€è¦çš„åˆ—
    if _rebalanced_time == "close":
        _all_factors_kline[["ä¸Šæ—¥_æ”¶ç›˜ä»·", "ä¸Šæ—¥_æ”¶ç›˜ä»·_å¤æƒ"]] = _all_factors_kline.groupby("è‚¡ç¥¨ä»£ç ")[
            ["æ”¶ç›˜ä»·", "æ”¶ç›˜ä»·_å¤æƒ"]
        ].shift(1)
    elif _rebalanced_time == "open":
        _all_factors_kline[["ä¸‹æ—¥_å¼€ç›˜ä»·", "ä¸‹æ—¥_å¼€ç›˜ä»·_å¤æƒ"]] = _all_factors_kline.groupby("è‚¡ç¥¨ä»£ç ")[
            ["å¼€ç›˜ä»·", "å¼€ç›˜ä»·_å¤æƒ"]
        ].shift(-1)
    elif _rebalanced_time not in ["close", "open", "close-open"]:
        _rebalanced_time_5min = _rebalanced_time.split("-")[0]
        _all_factors_kline[[f"ä¸‹æ—¥_{_rebalanced_time_5min}", f"ä¸‹æ—¥_{_rebalanced_time_5min}_å¤æƒ"]] = (
            _all_factors_kline.groupby("è‚¡ç¥¨ä»£ç ")[[f"{_rebalanced_time_5min}", f"{_rebalanced_time_5min}_å¤æƒ"]].shift(
                -1
            )
        )

    # ç¡®å®šåˆå¹¶çš„åˆ—å’Œæ—¥æœŸå­—æ®µ
    if _rebalanced_time == "close-open":
        buy_cols, sell_cols = ["å¼€ç›˜ä»·", "å¼€ç›˜ä»·_å¤æƒ"], ["æ”¶ç›˜ä»·", "æ”¶ç›˜ä»·_å¤æƒ"]
        buy_date, sell_date = "æŒæœ‰å¼€å§‹", "æŒæœ‰åˆ°æœŸ"
    elif _rebalanced_time == "close":
        buy_cols, sell_cols = ["ä¸Šæ—¥_æ”¶ç›˜ä»·", "ä¸Šæ—¥_æ”¶ç›˜ä»·_å¤æƒ"], ["æ”¶ç›˜ä»·", "æ”¶ç›˜ä»·_å¤æƒ"]
        buy_date, sell_date = "æŒæœ‰å¼€å§‹", "æŒæœ‰åˆ°æœŸ"
    elif _rebalanced_time == "open":
        buy_cols, sell_cols = ["å¼€ç›˜ä»·", "å¼€ç›˜ä»·_å¤æƒ"], ["ä¸‹æ—¥_å¼€ç›˜ä»·", "ä¸‹æ—¥_å¼€ç›˜ä»·_å¤æƒ"]
        buy_date, sell_date = "æŒæœ‰å¼€å§‹", "æŒæœ‰åˆ°æœŸ"
    else:
        _rebalanced_time_5min = _rebalanced_time.split("-")[0]
        buy_cols = [f"{_rebalanced_time_5min}", f"{_rebalanced_time_5min}_å¤æƒ"]
        sell_cols = [f"ä¸‹æ—¥_{_rebalanced_time_5min}", f"ä¸‹æ—¥_{_rebalanced_time_5min}_å¤æƒ"]
        buy_date, sell_date = "æŒæœ‰å¼€å§‹", "æŒæœ‰åˆ°æœŸ"

    # åˆ†åˆ«åˆå¹¶ä¹°å…¥ä»·æ ¼å’Œå–å‡ºä»·æ ¼
    _select = pd.merge(
        _select,
        _all_factors_kline[["äº¤æ˜“æ—¥æœŸ", "è‚¡ç¥¨ä»£ç "] + buy_cols],
        left_on=[buy_date, "è‚¡ç¥¨ä»£ç "],
        right_on=["äº¤æ˜“æ—¥æœŸ", "è‚¡ç¥¨ä»£ç "],
        how="left",
    ).drop(columns=["äº¤æ˜“æ—¥æœŸ"])

    _select = pd.merge(
        _select,
        _all_factors_kline[["äº¤æ˜“æ—¥æœŸ", "è‚¡ç¥¨ä»£ç "] + sell_cols],
        left_on=[sell_date, "è‚¡ç¥¨ä»£ç "],
        right_on=["äº¤æ˜“æ—¥æœŸ", "è‚¡ç¥¨ä»£ç "],
        how="left",
    ).drop(columns=["äº¤æ˜“æ—¥æœŸ"])

    # è®¡ç®—æ”¶ç›Šç‡
    _select["æŒæœ‰å‘¨æœŸæ”¶ç›Šç‡"] = (_select[sell_cols[1]] / _select[buy_cols[1]] - 1) * (1 - _c_rate * 2 - _t_rate)
    _select["æŒæœ‰å‘¨æœŸæ”¶ç›Šç‡"] = _select["æŒæœ‰å‘¨æœŸæ”¶ç›Šç‡"].round(4)

    return _select


# äº¤æ˜“è¡¨Â§
def get_trade_info(_select, _rebalanced_time):
    """
    æ•´ç†äº¤æ˜“ä¿¡æ¯ï¼Œç”¨äºhtmlå±•ç¤ºï¼Œé‡ç‚¹åœ¨ä¸ä¹°å…¥ä»·æ ¼å’Œå–å‡ºä»·æ ¼çš„ç¡®è®¤
    """
    df = _select.copy()
    common_map = {"æŒæœ‰å¼€å§‹": "ä¹°å…¥æ—¥æœŸ", "æŒæœ‰åˆ°æœŸ": "å–å‡ºæ—¥æœŸ", "æŒæœ‰å‘¨æœŸæ”¶ç›Šç‡": "æ”¶ç›Šç‡"}
    # ä¹°å…¥ä»·æ ¼å’Œå–å‡ºä»·æ ¼æ˜¯éå¤æƒä»·æ ¼
    specific_map = {
        "close-open": {"å¼€ç›˜ä»·": "ä¹°å…¥ä»·", "æ”¶ç›˜ä»·": "å–å‡ºä»·"},
        "open": {"å¼€ç›˜ä»·": "ä¹°å…¥ä»·", "ä¸‹æ—¥_å¼€ç›˜ä»·": "å–å‡ºä»·"},
        "close": {"ä¸Šæ—¥_æ”¶ç›˜ä»·": "ä¹°å…¥ä»·", "æ”¶ç›˜ä»·": "å–å‡ºä»·"},
    }

    if _rebalanced_time in specific_map:
        mapping = {**common_map, **specific_map[_rebalanced_time]}
    else:
        time_key = _rebalanced_time.split("-")[0]
        mapping = {**common_map, time_key: "ä¹°å…¥ä»·", f"ä¸‹æ—¥_{time_key}": "å–å‡ºä»·"}

    df.rename(columns=mapping, inplace=True)
    df["_æŒä»“å‘¨æœŸ"] = df["æŒä»“å‘¨æœŸ"].apply(lambda x: x.replace("_", ""))
    df = df.sort_values(["è‚¡ç¥¨ä»£ç ", "ä¹°å…¥æ—¥æœŸ"])
    return df[["è‚¡ç¥¨ä»£ç ", "_æŒä»“å‘¨æœŸ", "æŒä»“å‘¨æœŸ", "ä¹°å…¥æ—¥æœŸ", "å–å‡ºæ—¥æœŸ", "ä¹°å…¥ä»·", "å–å‡ºä»·", "æ”¶ç›Šç‡"]]


# æ£€æŸ¥å•ä¸ªè‚¡ç¥¨æ˜¯å¦å­˜åœ¨ç»˜å›¾æ‰€éœ€å› å­æ•°æ®
def check_factor_in_df(single_stock_df, main_factor_list, sub_factor_list):
    main_factor_list_filter = []
    sub_factor_list_filter = []

    err_factor = []
    for each_factor in main_factor_list:
        if each_factor["å› å­åç§°"] == "æŒ‡æ•°":
            main_factor_list_filter.append(each_factor)
        elif each_factor["å› å­åç§°"] in single_stock_df.columns:
            main_factor_list_filter.append(each_factor)
        else:
            err_factor.append(each_factor["å› å­åç§°"])
    for item in sub_factor_list:
        factor_names = item["å› å­åç§°"]
        common_factors = []
        for factor in factor_names:
            if (factor in single_stock_df.columns) or (factor == "æŒ‡æ•°"):
                common_factors.append(factor)
            else:
                err_factor.append(factor)
        if common_factors:
            sub_factor_list_filter.append({"å› å­åç§°": common_factors, "å›¾å½¢æ ·å¼": item["å›¾å½¢æ ·å¼"]})
    err_factor = list(set(err_factor))
    if len(err_factor):
        print(f'{"ã€".join(err_factor)} å› å­ä¸å­˜åœ¨')
    return main_factor_list_filter, sub_factor_list_filter


# æ±‡æ€»è‚¡ç¥¨äº¤æ˜“ä¿¡æ¯
def analyze_stock_selection(_select: pd.DataFrame):
    """
    å¯¹è‚¡ç¥¨æ•°æ®è¿›è¡Œåˆ†ç»„åˆ†æï¼Œè¿”å›å„è‚¡ç¥¨çš„ç»Ÿè®¡ç»“æœåŠæ€»ä½“æè¿°æ€§ç»Ÿè®¡æ•°æ®ã€‚
    """
    res_list = []  # å­˜å‚¨æ¯ä¸ªåˆ†ç»„çš„ç»“æœ

    # éå†æ¯ä¸ªè‚¡ç¥¨åˆ†ç»„
    for stock_name, group in _select.groupby(["è‚¡ç¥¨ä»£ç "]):
        # å¯¹æ¯ä¸ªåˆ†ç»„æŒ‰ç…§é€‰è‚¡æ—¥æœŸæ’åº
        group.sort_values(by="é€‰è‚¡æ—¥æœŸ", inplace=True)

        # åˆå§‹åŒ–ç»“æœä¸´æ—¶DataFrame
        res_temp = pd.DataFrame()
        res_temp.loc[0, "è‚¡ç¥¨ä»£ç "] = stock_name[0]
        res_temp.loc[0, "è‚¡ç¥¨åç§°"] = group["è‚¡ç¥¨åç§°"].iloc[-1]
        res_temp.loc[0, "é€‰ä¸­æ¬¡æ•°"] = len(group["é€‰è‚¡æ—¥æœŸ"].unique())
        res_temp.loc[0, "ç´¯è®¡æŒè‚¡å¤©æ•°"] = group["æŒæœ‰å¤©æ•°"].sum()
        offset_ret = []
        for offset in group["æŒä»“å‘¨æœŸ"].unique():
            offset_temp = group[group["æŒä»“å‘¨æœŸ"] == offset]
            offset_temp = offset_temp.sort_values(by=["é€‰è‚¡æ—¥æœŸ"])
            offset_ret.append((offset_temp["æŒæœ‰å‘¨æœŸæ”¶ç›Šç‡"] + 1).prod() - 1)
        res_temp.loc[0, "ç´¯è®¡æŒè‚¡æ”¶ç›Š"] = np.mean(offset_ret)
        res_temp.loc[0, "æ¬¡å‡æ”¶ç›Šç‡"] = group["æŒæœ‰å‘¨æœŸæ”¶ç›Šç‡"].mean()
        res_temp.loc[0, "é¦–æ¬¡é€‰ä¸­æ—¶é—´"] = group["é€‰è‚¡æ—¥æœŸ"].dt.date.iloc[0]
        res_temp.loc[0, "æœ€åé€‰ä¸­æ—¶é—´"] = group["é€‰è‚¡æ—¥æœŸ"].dt.date.iloc[-1]

        # æ’å…¥æŒæœ‰å‘¨æœŸåˆ—è¡¨
        res_temp["æŒæœ‰å‘¨æœŸ"] = ""  # èµ‹å€¼ä¸€ä¸ªç©ºå­—ç¬¦ä¸²ç¡®ä¿åˆ—ä¸ºobjectç±»å‹
        res_temp.at[0, "æŒæœ‰å‘¨æœŸ"] = group["æŒæœ‰å‘¨æœŸ"].to_list()

        # å°†å½“å‰åˆ†ç»„ç»“æœæ·»åŠ åˆ°ç»“æœåˆ—è¡¨
        res_list.append(res_temp)

    # æ±‡æ€»æ‰€æœ‰åˆ†ç»„çš„åˆ†æç»“æœ
    all_res = pd.concat(res_list, ignore_index=True)

    # å¯¹æ€»ä½“æ•°æ®è¿›è¡Œæè¿°æ€§ç»Ÿè®¡
    describe = pd.DataFrame()
    describe.loc[0, "é€‰è‚¡æ•°"] = all_res.shape[0]
    describe.loc[0, "å¹³å‡é€‰ä¸­æ¬¡æ•°"] = all_res["é€‰ä¸­æ¬¡æ•°"].mean()
    describe.loc[0, "å¹³å‡ç´¯è®¡æŒè‚¡å¤©æ•°"] = all_res["ç´¯è®¡æŒè‚¡å¤©æ•°"].mean()
    describe.loc[0, "å¹³å‡æ¬¡å‡æ”¶ç›Šç‡"] = all_res["æ¬¡å‡æ”¶ç›Šç‡"].mean()
    describe.loc[0, "å¹³å‡æŒè‚¡ç´¯è®¡æ”¶ç›Š"] = all_res["ç´¯è®¡æŒè‚¡æ”¶ç›Š"].mean()
    describe.loc[0, "é€‰è‚¡èƒœç‡"] = all_res[all_res["ç´¯è®¡æŒè‚¡æ”¶ç›Š"] > 0].shape[0] / describe.loc[0, "é€‰è‚¡æ•°"]

    return all_res, describe.T


# endregion


# ===== ç­–ç•¥æŸ¥çœ‹å™¨ä¸»å‡½æ•° =====
def main(_config):
    # è·å–é…ç½®ä¿¡æ¯
    _backtest_name = config["backtest_name"]
    _start_time = _config["start_time"]
    _end_time = _config["end_time"]
    _add_days = _config["add_days"]
    _strategy_name_temp = _config["strategy_name"]
    _add_factor_main_list = _config["add_factor_main_list"]
    _add_factor_sub_list = _config["add_factor_sub_list"]
    _color_dict = _config["color_dict"]
    config_global = load_config()

    # ç»Ÿä¸€å¤„ç†ï¼Œå°†å› å­åæ”¹ä¸ºä¸è¦ä»¥factor_å¼€å¤´çš„å› å­å
    for v in _add_factor_main_list:
        if v["å› å­åç§°"].startswith("factor_"):
            v["å› å­åç§°"] = v["å› å­åç§°"][7:]
    for v in _add_factor_sub_list:
        v["å› å­åç§°"] = [x[7:] if x.startswith("factor_") else x for x in v["å› å­åç§°"]]

    strategy_names_list = [strategy.name for strategy in config_global.strategy_list]

    # æ£€æŸ¥å¹¶è§„èŒƒç­–ç•¥åå­—
    # ç¬¬ä¸€ç§æƒ…å†µï¼šè¾“å…¥æ•°å­—ï¼Œç­–ç•¥ä½ç½®
    if isinstance(_strategy_name_temp, (int, float)):
        if _strategy_name_temp >= len(config_global.strategy_list) or _strategy_name_temp < 0:
            raise ValueError(f"{_strategy_name_temp} æ•°å­—è¾“å…¥ä¸ç¬¦åˆç­–ç•¥èŒƒå›´ï¼Œè¯·æ£€æŸ¥")
        _strategy_name = config_global.strategy_list[_strategy_name_temp].name

    # ç¬¬äºŒç§æƒ…å†µï¼Œè¾“å…¥å­—ç¬¦ä¸²
    elif isinstance(_strategy_name_temp, str):
        # å¦‚æœå­—ç¬¦ä¸²æ˜¯ç­–ç•¥nameï¼Œä¸”è€ƒè™‘é‡åæƒ…å†µï¼Œè‹¥é‡ååˆ™å–ç¬¬ä¸€ä¸ªç­–ç•¥
        if _strategy_name_temp in config_global.strategy_name_list:
            _strategy_name = next((x for x in strategy_names_list if _strategy_name_temp == x.split(".")[1]), None)
        # ç­–ç•¥æŒ‰ç…§è§„èŒƒåç§°è¾“å…¥
        elif _strategy_name_temp in strategy_names_list:
            _strategy_name = _strategy_name_temp
        else:
            raise ValueError(f"{_strategy_name_temp}åç§°è¾“å…¥æœ‰è¯¯ï¼Œè¯·æ£€æŸ¥")
    else:
        raise ValueError(f"{_strategy_name_temp} åç§°è¾“å…¥æœªæŒ‰ç…§è§„å®šçš„ä¸‰ç§æ–¹å¼è¾“å…¥ï¼Œè¯·æ£€æŸ¥")

    # åŠ è½½configè®¾ç½®
    c_rate = config_global.c_rate  # æ‰‹ç»­è´¹
    t_rate = config_global.t_rate  # å°èŠ±ç¨
    data_center_path = config_global.data_center_path  # æ•°æ®ä¸­å¿ƒè·¯å¾„ # å›æµ‹åç§°
    root_dir = config_global.get_result_folder().parent.parent  # æ ¹ç›®å½•
    results_dir = config_global.get_result_folder().parent / _backtest_name
    analysis_dir = os.path.join(root_dir, "åˆ†æç»“æœ/ç­–ç•¥æŸ¥çœ‹å™¨")  # åˆ†æç»“æœä¿å­˜ç›®å½•
    cache_dir = os.path.join(root_dir, "è¿è¡Œç¼“å­˜")  # ç­–ç•¥æ•°æ®ä¿å­˜è·¯å¾„

    # åˆå§‹åŒ–ç»“æœç›®å½•
    save_path, fig_save_path = init_directories(_strategy_name, _backtest_name, _start_time, _end_time, analysis_dir)

    # æ•´åˆé™¤Kçº¿å¤–çš„ç»˜å›¾æ•°æ®
    all_add_factor = [item["å› å­åç§°"] for item in _add_factor_main_list] + [
        name for item in _add_factor_sub_list for name in item["å› å­åç§°"]
    ]
    all_add_factor = list(set(all_add_factor))
    # å¦‚æœæ˜¯ factor_ å¼€å¤´çš„ï¼Œåˆ™åªä¿ç•™ååŠéƒ¨åˆ†
    all_add_factor = [factor[7:] if factor.startswith("factor_") else factor for factor in all_add_factor]

    # Kçº¿å¼€å§‹æ—¶é—´
    d_start = pd.to_datetime(_start_time) - pd.to_timedelta(f"{_add_days}d")  # æ—¥çº¿æ•°æ®å¼€å§‹æ—¶é—´
    # Kçº¿ç»“æŸæ—¶é—´
    d_end = pd.to_datetime(_end_time) + pd.to_timedelta(f"{_add_days}d")  # æ—¥çº¿æ•°æ®ç»“æŸæ—¶é—´

    # åˆå§‹åŒ–æ•°æ®
    select = load_select_data(_strategy_name, _start_time, _end_time, results_dir)
    stocks = list(select["è‚¡ç¥¨ä»£ç "].unique())
    all_factors_kline = load_kline_data(stocks, all_add_factor, cache_dir)
    period_offset_df = pd.read_csv(
        Path(data_center_path) / "period_offset.csv", encoding="gbk", skiprows=1, parse_dates=["äº¤æ˜“æ—¥æœŸ"]
    )
    index_data = tf.import_index_data(os.path.join(config_global.index_data_path, "sh000001.csv"), (d_start, d_end))

    # ç­–ç•¥æ¢ä»“æ—¶é—´
    rebalanced_time = select["æ¢ä»“æ—¶é—´"].unique()[0]

    # è®¡ç®—åˆ†é’Ÿå¤æƒä»·æ ¼
    all_factors_kline = calculate_adjusted_prices(all_factors_kline, rebalanced_time)

    # æ•´åˆä¸åŒoffsetçš„é€‰è‚¡å‘¨æœŸ
    select = merge_period_offset(select, period_offset_df)

    # å°±ç®—æŒæœ‰å‘¨æœŸå†…æ”¶ç›Š
    select = get_buy_sell_ret(all_factors_kline, select, rebalanced_time, c_rate, t_rate)

    # æ ‡å‡†åŒ–äº¤æ˜“ä¿¡æ¯
    select_trade_info = get_trade_info(select, rebalanced_time)

    # ç”Ÿæˆåˆ†ææ±‡æ€»è¡¨
    all_res, describe = analyze_stock_selection(select)
    describe.to_csv(save_path + "02_åˆ†ææ±‡æ€».csv", encoding="gbk", header=False)

    ## å¼€å§‹éå†æ¯ä¸€è¡Œæ•°æ®ç”»å›¾
    print("å¼€å§‹ç»˜åˆ¶ä¸ªè‚¡è¡Œæƒ…å›¾...")
    for i in all_res.index:
        # è·å–å¸ç§åç§°
        stock_code = all_res.loc[i, "è‚¡ç¥¨ä»£ç "]
        stock_name = all_res.loc[i, "è‚¡ç¥¨åç§°"]
        print(f"æ­£åœ¨ç»˜åˆ¶ï¼šç¬¬{i + 1}/{all_res.shape[0]}ä¸ª {stock_code}_{stock_name}")
        # è¯»å–è‚¡ç¥¨ä¿¡æ¯
        df = all_factors_kline[all_factors_kline["è‚¡ç¥¨ä»£ç "] == stock_code]
        if "æŒ‡æ•°" in all_add_factor:
            df = pd.merge(left=df, right=index_data, on="äº¤æ˜“æ—¥æœŸ", how="left", sort=True, indicator=True)

        # æˆªå–æ—¶é—´
        df = df[(df["äº¤æ˜“æ—¥æœŸ"] >= d_start) & (df["äº¤æ˜“æ—¥æœŸ"] <= d_end)]
        # è·å–æ‰€æœ‰çš„ä¹°å…¥æ—¶é—´ç‚¹
        open_times = [pd.to_datetime(time_range.split("--")[0]) for time_range in all_res.loc[i, "æŒæœ‰å‘¨æœŸ"]]
        # è·å–æ‰€æœ‰çš„å–å‡ºæ—¶é—´ç‚¹
        close_times = [pd.to_datetime(time_range.split("--")[1]) for time_range in all_res.loc[i, "æŒæœ‰å‘¨æœŸ"]]

        # åœ¨æ•°æ®ä¸­åŠ å…¥ä¹°å…¥ä¿¡æ¯
        df.loc[df["äº¤æ˜“æ—¥æœŸ"].isin(open_times), "ä¹°å…¥æ—¶é—´"] = "ä¹°å…¥"
        # åœ¨æ•°æ®ä¸­åŠ å…¥å–å‡ºä¿¡æ¯
        df.loc[df["äº¤æ˜“æ—¥æœŸ"].isin(close_times), "å–å‡ºæ—¶é—´"] = "å–å‡º"

        # äº§ç”Ÿäº¤æ˜“è¡¨
        trade_df = select_trade_info[select_trade_info["è‚¡ç¥¨ä»£ç "] == stock_code]
        _add_factor_main_list, _add_factor_sub_list = check_factor_in_df(
            df, _add_factor_main_list, _add_factor_sub_list
        )
        # ç»˜åˆ¶ä¸­æ€§ç­–ç•¥çš„ä¹°å–ä¿¡æ¯
        pf.draw_hedge_signal_plotly(
            df,
            index_data,
            fig_save_path,
            f"{stock_code}_{stock_name}",
            trade_df,
            all_res.loc[i],
            _add_factor_main_list,
            _add_factor_sub_list,
            _color_dict,
        )

        file_path = os.path.join(fig_save_path, f"{stock_code}_{stock_name}.html")
        all_res.loc[i, "è‚¡ç¥¨åç§°"] = f'=HYPERLINK("{file_path}","{stock_name}")'

    # ä¿å­˜ç»“æœ
    all_res.to_excel(save_path + "01_é€‰è‚¡åˆ†æç»“æœ.xlsx", index=False)


if __name__ == "__main__":
    # ===== ç­–ç•¥ä¿¡æ¯é…ç½® =====
    config = {
        # å›æµ‹ç»“æœåç§°ï¼Œä¸configä¸­ä¸€è‡´
        "backtest_name": "é€‰è‚¡æµ‹è¯•",
        # ç­–ç•¥åç§°ï¼Œè¾“å…¥æ ¼å¼ï¼šç­–ç•¥åç§°/é€‰è‚¡ç»“æœ (å¯åœ¨å›æµ‹ç»“æœæ–‡ä»¶å¤¹ä¸‹æŸ¥çœ‹)
        # è¿™é‡Œçš„è¾“å…¥å½¢å¼åŒ…æ‹¬ä¸‰ç§ï¼š1. configä¸­çš„strategy_listçš„ç­–ç•¥çš„ä½ç½®ä¿¡æ¯ï¼Œæ•°å­— 0ã€1ç­‰ (æ¯æ¬¡åªèƒ½è¾“å…¥ä¸€ä¸ªæ•°å­—)
        #                     2. configä¸­çš„strategy_listçš„ç­–ç•¥çš„è§„èŒƒåå­—ï¼Œç»“æ„ä¸º '#0.ç­–ç•¥1'(#.{ç­–ç•¥ä½ç½®ä¿¡æ¯ï¼Œæ•°å­—è¡¨ç¤º}.{ç­–ç•¥åå­—ï¼Œå¯¹åº”name})
        #                     3. configä¸­çš„strategy_listçš„ç­–ç•¥çš„nameï¼Œæ³¨æ„ï¼šå¦‚æœstrategy_listä¸­ç­–ç•¥çš„åå­—ä¸€æ ·ï¼Œä»£ç é»˜è®¤è¯»å–ç¬¬ä¸€ä¸ªï¼Œä¾‹å¦‚nameéƒ½ä¸ºå°å¸‚å€¼ï¼Œç­–ç•¥æŸ¥çœ‹å™¨ä»£ç é»˜è®¤è¯»å–ç¬¬ä¸€ä¸ªã€‚
        "strategy_name": 0,  # æ³¨æ„ç‚¹ï¼šå¦‚æœç­–ç•¥åŒ…å«å¤šä¸ªå­ç­–ç•¥ï¼Œå•æ¬¡ä»…æ”¯æŒå•ä¸ªé€‰å¸ç»“æœåˆ†æã€‚
        "start_time": "2021-04-01",  # åˆ†æå¼€å§‹æ—¶é—´
        "end_time": "2025-05-20",  # åˆ†æç»“æŸæ—¶é—´
        # ä¸»å›¾å¢åŠ (å’Œè‚¡ç¥¨Kçº¿å›¾åŒä¸€ç”»å¸ƒ),å‡ä¸ºæŠ˜çº¿å›¾ã€‚
        "add_factor_main_list": [
            {"å› å­åç§°": "æŒ‡æ•°", "æ¬¡åæ ‡è½´": True},
            {"å› å­åç§°": "factor_å½’æ¯å‡€åˆ©æ¶¦åŒæ¯”å¢é€Ÿ_60", "æ¬¡åæ ‡è½´": False},
            {"å› å­åç§°": "factor_å¸‚å€¼", "æ¬¡åæ ‡è½´": False},
        ],
        # é™„å›¾å¢åŠ (åœ¨Kçº¿å›¾ä¸‹æ–¹å±•ç¤º)ï¼Œä¸€ä¸ªdictä¸ºä¸€ä¸ªå­å›¾ï¼Œå› å­åç§°çš„listå¤§äº1ä¸ªå€¼ï¼Œåˆ™ä¼šè¢«ç”»åœ¨åŒä¸€ä¸ªå›¾ä¸­ï¼Œæ²¡ç”¨æ¬¡åæ ‡è½´æ¦‚å¿µ
        # å›¾å½¢æ ·å¼æœ‰ä¸”ä»…æœ‰ä¸‰ç§é€‰æ‹©Kçº¿å›¾\æŸ±çŠ¶å›¾\æŠ˜çº¿å›¾
        "add_factor_sub_list": [
            # {'å› å­åç§°': ['æ¢æ‰‹ç‡_20'], 'å›¾å½¢æ ·å¼': 'æŠ˜çº¿å›¾'},
            # {"å› å­åç§°": ["factor_å½’æ¯å‡€åˆ©æ¶¦åŒæ¯”å¢é€Ÿ_60"], "å›¾å½¢æ ·å¼": "æŠ˜çº¿å›¾"},
            # {"å› å­åç§°": ["factor_å¸‚å€¼"], "å›¾å½¢æ ·å¼": "æŸ±çŠ¶å›¾"},
            {"å› å­åç§°": ["factor_ROE_å•å­£"], "å›¾å½¢æ ·å¼": "æŠ˜çº¿å›¾"}
        ],
        # ===== ä»¥ä¸‹ä¿¡æ¯å‡ ä¹ä¸éœ€è¦é…ç½® =====
        "add_days": 120,  # Kçº¿å›¾éœ€è¦æå‰/å»¶é•¿çš„å¤©æ•°ï¼Œadd_daysæŒ‡å¼€å§‹æ—¶é—´æå‰120å¤©ï¼Œç»“æŸæ—¶é—´å¾€åå»¶é•¿120å¤©
        # æŒ‰å› å­åç§°æŒ‡å®šé¢œè‰²ï¼ŒKçº¿å±•ç¤ºçš„å†…å®¹å›ºå®šé¢œè‰²æŒ‡å®šæ— æ•ˆã€‚
        # é¢œè‰²ä»…ä¸ºplotlyæ”¯æŒçš„é¢œè‰²æ ¼å¼ï¼ŒåŸºæœ¬ä¸Šä½ çŸ¥é“çš„é¢œè‰²ç›¸å…³çš„è‹±æ–‡å•è¯éƒ½æœ‰ï¼Œæ²¡æœ‰ä¼šæŠ¥é”™ã€‚ ä¸æŒ‡å®šé¢œè‰²ä¼šéšæœºé…è‰²
        "color_dict": {"æŒ‡æ•°": "red"},
    }

    # è¿è¡Œä¸»å‡½æ•°
    main(config)
