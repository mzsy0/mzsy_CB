"""
é‚¢ä¸è¡Œï½œç­–ç•¥åˆ†äº«ä¼š
è‚¡ç¥¨é‡åŒ–ç­–ç•¥æ¡†æ¶ğ“Ÿğ“»ğ“¸

ç‰ˆæƒæ‰€æœ‰ Â©ï¸ é‚¢ä¸è¡Œ
å¾®ä¿¡: xbx1717

æœ¬ä»£ç ä»…ä¾›ä¸ªäººå­¦ä¹ ä½¿ç”¨ï¼Œæœªç»æˆæƒä¸å¾—å¤åˆ¶ã€ä¿®æ”¹æˆ–ç”¨äºå•†ä¸šç”¨é€”ã€‚

Author: é‚¢ä¸è¡Œ
"""

import gc
import sys
import time
import traceback
from concurrent.futures import ProcessPoolExecutor, as_completed
from typing import Dict, List

import numpy as np
import pandas as pd
from tqdm import tqdm

from config import n_jobs, factor_col_limit
from core.data_center import check_extra_data, merge_extra_data
from core.fin_essentials import merge_with_finance_data
from core.model.backtest_config import BacktestConfig
from core.model.factor_config import get_col_name
from core.utils.factor_hub import FactorHub
from core.utils.log_kit import logger
from core.utils.path_kit import get_file_path

# å› å­è®¡ç®—ä¹‹åï¼Œéœ€è¦ä¿å­˜çš„è¡Œæƒ…æ•°æ®
FACTOR_COLS = [
    "äº¤æ˜“æ—¥æœŸ",
    "è‚¡ç¥¨ä»£ç ",
    "è‚¡ç¥¨åç§°",
    "ä¸Šå¸‚è‡³ä»Šäº¤æ˜“å¤©æ•°",
    "å¤æƒå› å­",
    "å¼€ç›˜ä»·",
    "æœ€é«˜ä»·",
    "æœ€ä½ä»·",
    "æ”¶ç›˜ä»·",
    "æˆäº¤é¢",
    "æ˜¯å¦äº¤æ˜“",
    "æµé€šå¸‚å€¼",
    "æ€»å¸‚å€¼",
    "ä¸‹æ—¥_å¼€ç›˜æ¶¨åœ",
    "ä¸‹æ—¥_æ˜¯å¦ST",
    "ä¸‹æ—¥_æ˜¯å¦äº¤æ˜“",
    "ä¸‹æ—¥_æ˜¯å¦é€€å¸‚",
]
KLINE_COLS = ["äº¤æ˜“æ—¥æœŸ", "è‚¡ç¥¨ä»£ç ", "è‚¡ç¥¨åç§°"]
# è®¡ç®—å®Œé€‰è‚¡ä¹‹åï¼Œä¿ç•™çš„å­—æ®µ
RES_COLS = [
    "é€‰è‚¡æ—¥æœŸ",
    "è‚¡ç¥¨ä»£ç ",
    "è‚¡ç¥¨åç§°",
    "ç­–ç•¥",
    "æŒä»“å‘¨æœŸ",
    "æ¢ä»“æ—¶é—´",
    "ç›®æ ‡èµ„é‡‘å æ¯”",
    "æ‹©æ—¶ä¿¡å·",
    "é€‰è‚¡å› å­æ’å",
]


# ================================================================
# step2_è®¡ç®—å› å­.py
# ================================================================
def cal_strategy_factors(
    conf: BacktestConfig,
    stock_code,
    candle_df,
    fin_data: Dict[str, pd.DataFrame] = None,
    factor_col_name_list: List[str] = (),
):
    """
    è®¡ç®—æŒ‡å®šè‚¡ç¥¨çš„ç­–ç•¥å› å­ã€‚

    å‚æ•°:
    conf (BacktestConfig): ç­–ç•¥é…ç½®
    stock_code (str): è‚¡ç¥¨ä»£ç 
    candle_df (DataFrame): è‚¡ç¥¨çš„Kçº¿æ•°æ®ï¼Œå·²ç»æŒ‰ç…§"äº¤æ˜“æ—¥æœŸ"ä»å°åˆ°å¤§æ’åº
    fin_data (dict): è´¢åŠ¡æ•°æ®

    è¿”å›:
    DataFrame: åŒ…å«è®¡ç®—å› å­çš„Kçº¿æ•°æ®
    dict: å› å­åˆ—çš„å‘¨æœŸè½¬æ¢è§„åˆ™
    """
    factor_series_dict = {}
    before_len = len(candle_df)

    candle_df.sort_values(by="äº¤æ˜“æ—¥æœŸ", inplace=True)  # é˜²æ­¢å› å­è®¡ç®—å‡ºé”™ï¼Œè®¡ç®—ä¹‹å‰ï¼Œå…ˆè¿›è¡Œæ’åº
    for factor_name, param_list in conf.factor_params_dict.items():
        factor_file = FactorHub.get_by_name(factor_name)
        minutes_tuple_set = conf.factor_minutes_dict.get(factor_name, set(()))  # 2025-03-20æ·»åŠ åˆ†é’Ÿæ•°æ®çš„æ”¯æŒ
        for minutes_tuple in minutes_tuple_set:
            for param in param_list:
                col_name = get_col_name(factor_name, param, minutes_tuple)
                if col_name in factor_col_name_list:
                    # å› å­è®¡ç®—ï¼Œfactor_dfæ˜¯åŒ…å«å› å­è®¡ç®—ç»“æœçš„DataFrameï¼Œå¿…é¡»æ˜¯æŒ‰ç…§"äº¤æ˜“æ—¥æœŸ"ä»å°åˆ°å¤§æ’åº
                    factor_df = factor_file.add_factor(
                        candle_df.copy(),
                        param,
                        fin_data=fin_data,
                        col_name=col_name,
                        minutes=minutes_tuple,  # 2025-03-20æ·»åŠ åˆ†é’Ÿæ•°æ®çš„æ”¯æŒ
                    )

                    factor_series_dict[col_name] = factor_df[col_name].values
                    # æ£€æŸ¥å› å­è®¡ç®—æ˜¯å¦å‡ºé”™
                    if before_len != len(factor_series_dict[col_name]):
                        logger.error(
                            f"{stock_code}çš„{factor_name}å› å­({param}ï¼Œ{col_name})å¯¼è‡´æ•°æ®é•¿åº¦å‘ç”Ÿå˜åŒ–ï¼Œè¯·æ£€æŸ¥ï¼"
                        )
                        raise Exception("å› å­è®¡ç®—å‡ºé”™ï¼Œè¯·é¿å…åœ¨cal_factorsä¸­ä¿®æ”¹æ•°æ®è¡Œæ•°")

    kline_with_factor_dict = {**{col_name: candle_df[col_name] for col_name in FACTOR_COLS}, **factor_series_dict}
    kline_with_factor_df = pd.DataFrame(kline_with_factor_dict)
    kline_with_factor_df.sort_values(by="äº¤æ˜“æ—¥æœŸ", inplace=True)

    # æ ¹æ®å›æµ‹è®¾ç½®çš„æ—¶é—´åŒºé—´è¿›è¡Œè£åˆ‡
    start_date = conf.start_date or kline_with_factor_df["äº¤æ˜“æ—¥æœŸ"].min()
    end_date = conf.end_date or kline_with_factor_df["äº¤æ˜“æ—¥æœŸ"].max()
    date_cut_condition = (kline_with_factor_df["äº¤æ˜“æ—¥æœŸ"] >= start_date) & (
        kline_with_factor_df["äº¤æ˜“æ—¥æœŸ"] <= end_date
    )

    return kline_with_factor_df[date_cut_condition].reset_index(drop=True)  # è¿”å›è®¡ç®—å®Œçš„å› å­æ•°æ®


def process_by_stock(conf: BacktestConfig, candle_df: pd.DataFrame, factor_col_name_list: List[str], idx: int):
    """
    ç»„è£…å› å­è®¡ç®—å¿…è¦çš„æ•°æ®ç»“æ„ï¼Œå¹¶ä¸”é€å…¥åˆ°å› å­è®¡ç®—å‡½æ•°ä¸­è¿›è¡Œè®¡ç®—
    :param conf: å›æµ‹ç­–ç•¥é…ç½®
    :param candle_df: å•åªè‚¡ç¥¨çš„Kçº¿æ•°æ®
    :param factor_col_name_list: éœ€è¦è®¡ç®—çš„å› å­åˆ—åç§°åˆ—è¡¨
    :param idx: è‚¡ç¥¨ç´¢å¼•
    :return: idx, factor_df
    """
    stock_code = candle_df.iloc[-1]["è‚¡ç¥¨ä»£ç "]
    # å¯¼å…¥è´¢åŠ¡æ•°æ®ï¼Œå°†ä¸ªè‚¡æ•°æ®ä¸è´¢åŠ¡æ•°æ®åˆå¹¶ï¼Œå¹¶è®¡ç®—è´¢åŠ¡æŒ‡æ ‡çš„è¡ç”ŸæŒ‡æ ‡
    if conf.fin_cols:  # å‰é¢å·²ç»åšäº†é¢„æ£€ï¼Œè¿™è¾¹åªéœ€è¦åŠ¨æ€å°å—ä½³å³å¯
        # åˆ†åˆ«ä¸ºï¼šä¸ªè‚¡æ•°æ®ã€è´¢åŠ¡æ•°æ®ã€åŸå§‹è´¢åŠ¡æ•°æ®ï¼ˆä¸æŠ›å¼ƒåºŸå¼ƒçš„æŠ¥å‘Šæ•°æ®ï¼‰
        candle_df, fin_df, raw_fin_df = merge_with_finance_data(conf, stock_code, candle_df)
        fin_data = {"è´¢åŠ¡æ•°æ®": fin_df, "åŸå§‹è´¢åŠ¡æ•°æ®": raw_fin_df}
    else:
        fin_data = None

    if conf.extra_data:
        # ä¸ªè‚¡æ•°æ®ä¸å…¶ä»–æ•°æ®åˆå¹¶
        for data_name in conf.extra_data.keys():
            candle_df = merge_extra_data(candle_df, data_name, conf.extra_data[data_name])

    factor_df = cal_strategy_factors(conf, stock_code, candle_df, fin_data, factor_col_name_list)

    return idx, factor_df


def calculate_factors(conf: BacktestConfig, boost: bool = True):
    """
    è®¡ç®—æ‰€æœ‰è‚¡ç¥¨çš„å› å­ï¼Œåˆ†ä¸ºä¸‰æ­¥ï¼š
    1. åŠ è½½è‚¡ç¥¨Kçº¿æ•°æ®
    2. è®¡ç®—æ¯ä¸ªè‚¡ç¥¨çš„å› å­ï¼Œå¹¶å­˜å‚¨åˆ°åˆ—è¡¨
    3. åˆå¹¶æ‰€æœ‰å› å­æ•°æ®å¹¶å­˜å‚¨

    å‚æ•°:
    conf (BacktestConfig): å›æµ‹é…ç½®
    """
    logger.info(f"å› å­è®¡ç®—...")
    s_time = time.time()

    # ====================================================================================================
    # 1. åŠ è½½è‚¡ç¥¨Kçº¿æ•°æ®
    # ====================================================================================================
    logger.debug("ğŸ›‚ é…ç½®ä¿¡æ¯æ£€æŸ¥...")
    if len(conf.fin_cols) > 0 and not conf.has_fin_data:
        logger.warning(f"ç­–ç•¥éœ€è¦è´¢åŠ¡å› å­{conf.fin_cols}ï¼Œä½†ç¼ºå°‘è´¢åŠ¡æ•°æ®è·¯å¾„")
        raise ValueError("è¯·åœ¨ config.py ä¸­é…ç½®è´¢åŠ¡æ•°æ®è·¯å¾„")
    elif len(conf.fin_cols) > 0:
        logger.debug(f"â„¹ï¸ æ£€æµ‹åˆ°è´¢åŠ¡å› å­ï¼š{conf.fin_cols}")
    else:
        logger.debug("â„¹ï¸ æ£€æµ‹åˆ°æ²¡æœ‰è´¢åŠ¡å› å­")

    if len(conf.extra_data.keys()) > 0:
        logger.debug(f"ğŸ” æ£€æµ‹åˆ°å¤–éƒ¨æ•°æ®ï¼š{list(conf.extra_data.keys())}")
        for data_name in conf.extra_data.keys():
            is_ok, msg = check_extra_data(data_name)
            if not is_ok:
                logger.error(f"å¤–éƒ¨æ•°æ®æ£€æµ‹å¤±è´¥ï¼š{msg}")
                sys.exit(2)
    else:
        logger.debug("ğŸ” æ£€æµ‹åˆ°æ²¡æœ‰å¤–éƒ¨æ•°æ®")

    logger.debug("ğŸ’¿ è¯»å–è‚¡ç¥¨Kçº¿æ•°æ®...")
    candle_df_dict: Dict[str, pd.DataFrame] = pd.read_pickle(conf.get_runtime_folder() / "è‚¡ç¥¨é¢„å¤„ç†æ•°æ®.pkl")

    # ====================================================================================================
    # 2. è®¡ç®—å› å­å¹¶å­˜å‚¨ç»“æœ
    # ====================================================================================================
    factor_col_count = len(conf.factor_col_name_list)
    shards = range(0, factor_col_count, factor_col_limit)

    logger.debug(
        f"""* æ€»å…±è®¡ç®—å› å­ä¸ªæ•°ï¼š{factor_col_count} ä¸ª
* å•æ¬¡è®¡ç®—å› å­ä¸ªæ•°ï¼š{factor_col_limit} ä¸ªï¼Œ(éœ€åˆ†æˆ{len(shards)}ç»„è®¡ç®—)
* éœ€è¦è®¡ç®—å¸ç§æ•°é‡ï¼š{len(candle_df_dict.keys())} ä¸ª"""
    )

    # æ¸…ç† cache çš„ç¼“å­˜
    all_kline_pkl = conf.get_runtime_folder() / "all_factors_kline.pkl"
    all_kline_pkl.unlink(missing_ok=True)

    # ** æ³¨æ„ **
    # `tqdm`æ˜¯ä¸€ä¸ªæ˜¾ç¤ºä¸ºè¿›åº¦æ¡çš„ï¼Œéå¸¸æœ‰ç”¨çš„å·¥å…·
    # ç›®å‰æ˜¯ä¸²è¡Œæ¨¡å¼ï¼Œæ¯”è¾ƒé€‚åˆdebugå’Œæµ‹è¯•ã€‚
    logger.debug(f"ğŸš€ å¤šè¿›ç¨‹è®¡ç®—å› å­ï¼Œè¿›ç¨‹æ•°é‡ï¼š{n_jobs}" if boost else "ğŸš² å•è¿›ç¨‹è®¡ç®—å› å­")
    for shard_index in shards:
        logger.debug(f"ğŸ—‚ï¸ å› å­åˆ†ç‰‡è®¡ç®—ä¸­ï¼Œè¿›åº¦ï¼š{int(shard_index / factor_col_limit) + 1}/{len(shards)}")
        factor_col_name_list = conf.factor_col_name_list[shard_index : shard_index + factor_col_limit]

        all_factor_df_list = [pd.DataFrame()] * len(candle_df_dict.keys())  # è®¡ç®—ç»“æœä¼šå­˜å‚¨åœ¨è¿™ä¸ªåˆ—è¡¨
        # factor_col_info = dict()
        if boost:
            with ProcessPoolExecutor(max_workers=n_jobs) as executor:
                futures = []
                for candle_idx, candle_df in enumerate(candle_df_dict.values()):
                    futures.append(executor.submit(process_by_stock, conf, candle_df, factor_col_name_list, candle_idx))

                for future in tqdm(futures, desc="ğŸ§® è®¡ç®—å› å­", total=len(futures), mininterval=2, file=sys.stdout):
                    idx, period_df = future.result()
                    # factor_col_info.update(agg_dict)  # æ›´æ–°å› å­åˆ—çš„å‘¨æœŸè½¬æ¢è§„åˆ™
                    all_factor_df_list[idx] = period_df
        else:
            for candle_idx, candle_df in tqdm(
                enumerate(candle_df_dict.values()),
                desc="ğŸ§® è®¡ç®—å› å­",
                total=len(candle_df_dict.keys()),
                mininterval=2,
                file=sys.stdout,
            ):
                try:
                    idx, period_df = process_by_stock(conf, candle_df, factor_col_name_list, candle_idx)
                except Exception as e:
                    logger.debug(traceback.format_exc())
                    logger.error(f"å› å­è®¡ç®—å¤±è´¥ï¼Œ{e}")
                    logger.error(f'è‚¡ç¥¨ä»£ç ï¼š{candle_df.iloc[-1]["è‚¡ç¥¨ä»£ç "]}')
                    logger.error(f"å› å­åç§°ï¼š{factor_col_name_list}")
                    raise e
                # factor_col_info.update(agg_dict)  # æ›´æ–°å› å­åˆ—çš„å‘¨æœŸè½¬æ¢è§„åˆ™
                all_factor_df_list[idx] = period_df

        # ====================================================================================================
        # 3. åˆå¹¶å› å­æ•°æ®å¹¶å­˜å‚¨
        # ====================================================================================================
        all_factors_df = pd.concat(all_factor_df_list, ignore_index=True, copy=False)
        logger.debug("ğŸ“… å› å­ç»“æœæœ€æ™šæ—¥æœŸï¼š" + str(all_factors_df["äº¤æ˜“æ—¥æœŸ"].max()))

        # è½¬åŒ–ä¸€ä¸‹symbolçš„ç±»å‹ä¸ºcategoryï¼Œå¯ä»¥åŠ å¿«å› å­è®¡ç®—é€Ÿåº¦ï¼ŒèŠ‚çœå†…å­˜
        # å¹¶ä¸”æ’åºå’Œæ•´ç†index
        all_factors_df = (
            all_factors_df.assign(
                è‚¡ç¥¨ä»£ç =all_factors_df["è‚¡ç¥¨ä»£ç "].astype("category"),
                è‚¡ç¥¨åç§°=all_factors_df["è‚¡ç¥¨åç§°"].astype("category"),
            )
            .sort_values(by=["äº¤æ˜“æ—¥æœŸ", "è‚¡ç¥¨ä»£ç "])
            .reset_index(drop=True)
        )

        logger.debug("ğŸ’¾ å­˜å‚¨å› å­æ•°æ®...")

        logger.debug(f"- {all_kline_pkl}")
        logger.debug(f'æœ€æ™šäº¤æ˜“æ—¥æœŸï¼š{all_factors_df["äº¤æ˜“æ—¥æœŸ"].max()}')

        # é€‰è‚¡éœ€è¦çš„kçº¿
        if not all_kline_pkl.exists():
            all_kline_df = all_factors_df[FACTOR_COLS].sort_values(by=["äº¤æ˜“æ—¥æœŸ", "è‚¡ç¥¨ä»£ç ", "è‚¡ç¥¨åç§°"])
            all_kline_df.to_pickle(all_kline_pkl)

        # é’ˆå¯¹æ¯ä¸€ä¸ªå› å­è¿›è¡Œå­˜å‚¨
        for factor_col_name in factor_col_name_list:
            factor_pkl = conf.get_runtime_folder() / f"factor_{factor_col_name}.pkl"
            factor_pkl.unlink(missing_ok=True)  # åŠ¨æ€æ¸…ç†æ‰cacheçš„ç¼“å­˜
            all_factors_df[factor_col_name].to_pickle(factor_pkl)

        gc.collect()

    logger.ok(f"å› å­è®¡ç®—å®Œæˆï¼Œè€—æ—¶ï¼š{time.time() - s_time:.2f}ç§’")


# ================================================================
# step3_é€‰è‚¡.py
# ================================================================
def select_stocks(confs: BacktestConfig | List[BacktestConfig], boost=True):
    if isinstance(confs, BacktestConfig):
        # å¦‚æœæ˜¯å•ä¾‹ï¼Œå°±ç›´æ¥è¿”å›åŸæ¥çš„ç»“æœ
        return select_stock_by_conf(confs, boost=boost)

    # å¦åˆ™å°±ç›´æ¥å¹¶è¡Œå›æµ‹
    is_silent = True  # å‡å°‘è¾“å‡º
    if boost:
        with ProcessPoolExecutor(max_workers=n_jobs) as executor:
            futures = [executor.submit(select_stock_by_conf, conf, boost, is_silent) for conf in confs]
            for future in tqdm(as_completed(futures), total=len(confs), desc="é€‰è‚¡", mininterval=2, file=sys.stdout):
                try:
                    future.result()
                except Exception as e:
                    logger.exception(e)
                    sys.exit(1)
    else:
        for conf in tqdm(confs, total=len(confs), desc="é€‰è‚¡", mininterval=2, file=sys.stdout):
            select_stock_by_conf(conf, boost, is_silent)

    import logging

    logger.setLevel(logging.DEBUG)  # æ¢å¤æ—¥å¿—æ¨¡å¼


def select_stock_by_conf(conf: BacktestConfig, boost=True, silent=False):
    """
    é€‰è‚¡æµç¨‹ï¼š
    1. åˆå§‹åŒ–ç­–ç•¥é…ç½®
    2. åŠ è½½å¹¶æ¸…æ´—é€‰è‚¡æ•°æ®
    3. è®¡ç®—é€‰è‚¡å› å­å¹¶è¿›è¡Œç­›é€‰
    4. ç¼“å­˜é€‰è‚¡ç»“æœ

    å‚æ•°:
    conf (BacktestConfig): å›æµ‹é…ç½®
    è¿”å›:
    DataFrame: é€‰è‚¡ç»“æœ
    """
    if silent:
        import logging

        logger.setLevel(logging.WARNING)  # å¯ä»¥å‡å°‘ä¸­é—´è¾“å‡ºçš„log

    result_folder = conf.get_result_folder()  # é€‰è‚¡ç»“æœæ–‡ä»¶å¤¹
    period_offset = conf.load_period_offset()  # äº¤æ˜“æ—¥æœŸåç§»
    factor_df_path = conf.get_runtime_folder() / "all_factors_kline.pkl"  # åœ¨è¿›ç¨‹ä¸­ï¼Œè¿™ä¸ªä½ç½®ä¼šæ— æ³•åŒºåˆ†å®ç›˜å’Œå›æµ‹

    logger.debug(f"ğŸ” å› å­æ–‡ä»¶ï¼š{factor_df_path}")

    if boost:
        # å¤šè¿›ç¨‹æ¨¡å¼
        with ProcessPoolExecutor() as executor:
            futures = [
                executor.submit(select_stocks_by_strategy, stg, factor_df_path, result_folder, period_offset)
                for stg in conf.strategy_list
            ]

            for future in as_completed(futures):
                try:
                    future.result()
                except Exception as e:
                    logger.exception(e)
                    sys.exit(1)
    else:
        for strategy in conf.strategy_list:
            select_stocks_by_strategy(strategy, factor_df_path, result_folder, period_offset)


def select_stocks_by_strategy(strategy, factor_df_path, result_folder, period_offset):
    # ====================================================================================================
    # 1. åˆå§‹åŒ–ç­–ç•¥é…ç½®
    # ====================================================================================================
    s_time = time.time()
    logger.debug(f"ğŸ¯ {strategy.name} é€‰è‚¡å¯åŠ¨...")

    # ====================================================================================================
    # 2. åŠ è½½å¹¶æ¸…æ´—é€‰è‚¡æ•°æ®
    # ====================================================================================================
    # å‡†å¤‡é€‰å¸ç”¨æ•°æ®
    runtime_folder = factor_df_path.parent
    factor_df = pd.read_pickle(factor_df_path)
    for factor_col_name in strategy.factor_columns:
        factor_df[factor_col_name] = pd.read_pickle(get_file_path(runtime_folder, f"factor_{factor_col_name}.pkl"))
    logger.debug(f'ğŸ“¦ [{strategy.name}] é€‰è‚¡æ•°æ®åŠ è½½å®Œæˆï¼Œæœ€æ™šæ—¥æœŸï¼š{factor_df["äº¤æ˜“æ—¥æœŸ"].max()}')
    # æ ¹æ®æŒä»“å‘¨æœŸè£åˆ‡
    select_dates_dict = {}
    select_dates = []
    for hold_period_name in strategy.hold_period_name_list:
        select_dates_dict[hold_period_name] = period_offset.groupby(hold_period_name)["äº¤æ˜“æ—¥æœŸ"].last().to_list()
        select_dates += select_dates_dict[hold_period_name]

    select_dates = list(set(select_dates))

    # è¿‡æ»¤æ‰æ¯ä¸€ä¸ªå‘¨æœŸä¸­ï¼Œæ²¡æœ‰äº¤æ˜“çš„è‚¡ç¥¨ & é’ˆå¯¹é€‰è‚¡æ—¥æœŸè¿›è¡Œç­›é€‰è¦é€‰è‚¡çš„æ•°æ®ï¼Œ
    # 2025-03-30 ä¸ºäº†ä¿è¯æ•°æ®çš„è¿ç»­æ€§ï¼Œæ—¥æœŸçš„ç­›é€‰éœ€è¦é˜²åœ¨åé¢
    factor_df = (
        factor_df[
            (factor_df["æ˜¯å¦äº¤æ˜“"] == 1)
            & (factor_df["äº¤æ˜“æ—¥æœŸ"].between(min(select_dates), max(select_dates), inclusive="both"))
        ]
        .dropna(subset=strategy.factor_columns)
        .copy()
    )
    factor_df.dropna(subset=["è‚¡ç¥¨ä»£ç "], inplace=True)

    # æœ€åæ•´ç†ä¸€ä¸‹
    factor_df.sort_values(by=["äº¤æ˜“æ—¥æœŸ", "è‚¡ç¥¨ä»£ç "], inplace=True)
    factor_df.reset_index(drop=True, inplace=True)

    logger.debug(f'â¡ï¸ [{strategy.name}] æ•°æ®æ¸…æ´—å®Œæˆï¼Œå»æ‰ç©ºå› å­æ•°æ®ï¼Œæœ€æ™šæ—¥æœŸï¼š{factor_df["äº¤æ˜“æ—¥æœŸ"].max()}')

    # ====================================================================================================
    # 3. å› å­è®¡ç®—å’Œç­›é€‰æµç¨‹
    # 3.1 å‰ç½®ç­›é€‰
    # 3.2 è®¡ç®—é€‰è‚¡å› å­
    # 3.3 åŸºäºé€‰è‚¡å› å­è¿›è¡Œé€‰è‚¡
    # ====================================================================================================

    # 3.1 å‰ç½®ç­›é€‰
    s = time.time()
    factor_df = strategy.filter_before_select(factor_df)
    factor_df = factor_df[KLINE_COLS + strategy.factor_columns]  # è£åˆ‡ä¸€ä¸‹æ•°æ®
    logger.debug(
        f"â¡ï¸ [{strategy.name}] å‰ç½®ç­›é€‰è€—æ—¶ï¼š{time.time() - s:.2f}sã€‚" f'æ•°æ®æœ€æ™šæ—¥æœŸï¼š{factor_df["äº¤æ˜“æ—¥æœŸ"].max()}'
    )

    # 3.2 è®¡ç®—é€‰è‚¡å› å­
    s = time.time()
    factor_df = strategy.calc_select_factor(factor_df)
    logger.debug(
        f"â¡ï¸ [{strategy.name}] é€‰è‚¡å¤åˆå› å­è®¡ç®—è€—æ—¶ï¼š{time.time() - s:.2f}sã€‚"
        f'æ•°æ®æœ€æ™šæ—¥æœŸï¼š{factor_df["äº¤æ˜“æ—¥æœŸ"].max()}'
    )

    # 3.3 è®¡ç®—å®šé£æ³¢ä¿¡å·ï¼ˆå’Œå¤æ™®äº2025-03-23 14:00ç¡®è®¤ï¼Œç›®å‰æ˜¯åœ¨è¿‡æ»¤ååšçš„æ‹©æ—¶ï¼‰
    s = time.time()
    if strategy.timing:
        signals = strategy.calc_signal(factor_df)
    else:
        signals = pd.DataFrame({"æ‹©æ—¶ä¿¡å·": 1}, index=sorted(factor_df["äº¤æ˜“æ—¥æœŸ"].unique()))
    logger.debug(f"â¡ï¸ [{strategy.name}] å®šé£æ³¢æ‹©æ—¶ï¼š{time.time() - s:.2f}s")

    # 3.4 è¿›è¡Œé€‰è‚¡
    s = time.time()
    # å…ˆæŒ‰ç…§select_datesè¿›è¡Œç­›é€‰
    factor_df = factor_df[factor_df["äº¤æ˜“æ—¥æœŸ"].isin(select_dates)]
    # å¼€å§‹ç­›é€‰
    result_df = select_by_factor(factor_df, strategy.select_num, strategy.factor_name)
    logger.debug(
        f"â¡ï¸ [{strategy.name}] é€‰è‚¡è€—æ—¶ï¼š{time.time() - s:.2f}sã€‚" f'æ•°æ®æœ€æ™šæ—¥æœŸï¼š{result_df["äº¤æ˜“æ—¥æœŸ"].max()}'
    )

    # 3.5 é€‰è‚¡åç½®è¿‡æ»¤
    # é¢„ç•™ä¸€ä¸‹ä½ç½®ç»™åç½®è¿‡æ»¤å“¦ï½

    result_path = result_folder / f"é€‰è‚¡ç»“æœ{strategy.name}.pkl"
    # è‹¥æ— é€‰è‚¡ç»“æœåˆ™ç›´æ¥è¿”å›
    if result_df.empty:
        pd.DataFrame(columns=[RES_COLS, strategy.factor_name]).to_pickle(result_path)
        return

    # 3.6 åˆå¹¶æ‹©æ—¶ä¿¡å·ï¼ˆå®šé£æ³¢ï¼‰
    result_df = pd.merge(result_df, signals, left_on="äº¤æ˜“æ—¥æœŸ", right_index=True, how="left")
    result_df["æ‹©æ—¶ä¿¡å·"] = result_df["æ‹©æ—¶ä¿¡å·"].fillna(1)
    signals.to_pickle(result_folder / f"æ‹©æ—¶ä¿¡å·{strategy.name}.pkl")
    signals.to_csv(result_folder / f"æ‹©æ—¶ä¿¡å·{strategy.name}.csv", index=True, encoding="utf-8-sig")

    # ====================================================================================================
    # 4. ç¼“å­˜é€‰è‚¡ç»“æœ
    # ====================================================================================================
    period_result_df_list = []
    result_df = result_df[[*KLINE_COLS, "ç›®æ ‡èµ„é‡‘å æ¯”", "æ‹©æ—¶ä¿¡å·", "é€‰è‚¡å› å­æ’å", strategy.factor_name]]
    for hold_period_name in strategy.hold_period_name_list:
        result_by_period = result_df[result_df["äº¤æ˜“æ—¥æœŸ"].isin(select_dates_dict[hold_period_name])].copy()
        result_by_period["æŒä»“å‘¨æœŸ"] = hold_period_name
        period_result_df_list.append(result_by_period)

    select_result_df = pd.concat(period_result_df_list, ignore_index=True, copy=False)

    select_result_df = select_result_df.assign(
        ç­–ç•¥=strategy.name, ç­–ç•¥æƒé‡=np.float64(strategy.cap_weight), æ¢ä»“æ—¶é—´=strategy.rebalance_time
    ).rename(columns={"äº¤æ˜“æ—¥æœŸ": "é€‰è‚¡æ—¥æœŸ"})

    select_result_df = select_result_df.assign(
        ç­–ç•¥=select_result_df["ç­–ç•¥"].astype("category"),
        æ¢ä»“æ—¶é—´=select_result_df["æ¢ä»“æ—¶é—´"].astype("category"),
        æŒä»“å‘¨æœŸ=select_result_df["æŒä»“å‘¨æœŸ"].astype("category"),
        ç›®æ ‡èµ„é‡‘å æ¯”_åŸå§‹=select_result_df["ç›®æ ‡èµ„é‡‘å æ¯”"],
        ç›®æ ‡èµ„é‡‘å æ¯”=(
            select_result_df["ç›®æ ‡èµ„é‡‘å æ¯”"]
            * select_result_df["æ‹©æ—¶ä¿¡å·"]
            * select_result_df["ç­–ç•¥æƒé‡"]
            / len(strategy.offset_list)
        ).astype(
            np.float64
        ),  # ç›®æ ‡èµ„é‡‘å æ¯”è½¬ä¸ºfloat64
        # æ ¹æ®ç­–ç•¥èµ„é‡‘æƒé‡ï¼Œè°ƒæ•´ç›®æ ‡åˆ†é…æ¯”ä¾‹ï¼Œå¹¶ä¸”å¹³å‡åˆ†é…åˆ°offsetä¸Š
    )

    # ç¼“å­˜åˆ°æœ¬åœ°æ–‡ä»¶
    select_result_df = select_result_df[RES_COLS]
    select_result_df.to_pickle(result_path)

    logger.debug(f"ğŸ [{strategy.name}] é€‰è‚¡è€—æ—¶: {(time.time() - s_time):.2f}s")

    return select_result_df


def select_by_factor(period_df, select_num: float | int, factor_name):
    """
    åŸºäºå› å­é€‰æ‹©ç›®æ ‡è‚¡ç¥¨å¹¶è®¡ç®—èµ„é‡‘æƒé‡ã€‚

    å‚æ•°:
    period_df (DataFrame): ç­›é€‰åçš„æ•°æ®
    select_num (float | int): é€‰è‚¡æ•°é‡æˆ–æ¯”ä¾‹
    factor_name (str): é€‰è‚¡å› å­åç§°

    è¿”å›:
    DataFrame: å¸¦ç›®æ ‡èµ„é‡‘å æ¯”çš„é€‰è‚¡ç»“æœ
    """
    period_df = calc_select_factor_rank(period_df, factor_column=factor_name, ascending=True)

    # åŸºäºæ’åç­›é€‰è‚¡ç¥¨
    if int(select_num) == 0:  # é€‰è‚¡æ•°é‡æ˜¯ç™¾åˆ†æ¯”
        period_df = period_df[period_df["é€‰è‚¡å› å­æ’å"] <= period_df["æ€»è‚¡æ•°"] * select_num].copy()
    else:  # é€‰è‚¡æ•°é‡æ˜¯å›ºå®šçš„æ•°å­—
        period_df = period_df[period_df["é€‰è‚¡å› å­æ’å"] <= select_num].copy()

    # æ ¹æ®é€‰è‚¡æ•°é‡åˆ†é…ç›®æ ‡èµ„é‡‘
    period_df["ç›®æ ‡èµ„é‡‘å æ¯”"] = 1 / period_df.groupby("äº¤æ˜“æ—¥æœŸ")["è‚¡ç¥¨ä»£ç "].transform("size")

    period_df.sort_values(by="äº¤æ˜“æ—¥æœŸ", inplace=True)
    period_df.reset_index(drop=True, inplace=True)

    # æ¸…ç†æ— å…³åˆ—
    period_df.drop(columns=["æ€»è‚¡æ•°"], inplace=True)

    return period_df


def calc_select_factor_rank(df, factor_column="å› å­", ascending=True):
    """
    è®¡ç®—å› å­æ’åã€‚

    å‚æ•°:
    df (DataFrame): åŸå§‹æ•°æ®
    factor_column (str): å› å­åˆ—å
    ascending (bool): æ’åºé¡ºåºï¼ŒTrueä¸ºå‡åº

    è¿”å›:
    DataFrame: åŒ…å«æ’åçš„åŸæ•°æ®
    """
    # è®¡ç®—å› å­çš„åˆ†ç»„æ’å
    df["é€‰è‚¡å› å­æ’å"] = df.groupby("äº¤æ˜“æ—¥æœŸ")[factor_column].rank(method="min", ascending=ascending)
    # æ ¹æ®æ—¶é—´å’Œå› å­æ’åæ’åº
    df.sort_values(by=["äº¤æ˜“æ—¥æœŸ", "é€‰è‚¡å› å­æ’å"], inplace=True)
    # é‡æ–°è®¡ç®—ä¸€ä¸‹æ€»è‚¡æ•°
    df["æ€»è‚¡æ•°"] = df.groupby("äº¤æ˜“æ—¥æœŸ")["è‚¡ç¥¨ä»£ç "].transform("size")
    return df


def concat_select_results(conf: BacktestConfig) -> pd.DataFrame:
    """
    èšåˆç­–ç•¥é€‰è‚¡ç»“æœï¼Œå½¢æˆç»¼åˆé€‰è‚¡ç»“æœ
    :param conf:
    :return:
    """
    # å¦‚æœæ˜¯çº¯å¤šå¤´ç°è´§æ¨¡å¼ï¼Œé‚£ä¹ˆå°±ä¸è½¬æ¢åˆçº¦æ•°æ®ï¼Œåªä¸‹ç°è´§å•
    all_select_df_list = []  # å­˜å‚¨æ¯ä¸€ä¸ªç­–ç•¥çš„é€‰è‚¡ç»“æœ
    result_folder = conf.get_result_folder()
    recent_select_df_list = []

    for strategy in conf.strategy_list:
        stg_select_result = result_folder / f"é€‰è‚¡ç»“æœ{strategy.name}.pkl"
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°±è·³è¿‡
        if not stg_select_result.exists():
            continue
        # è¯»å…¥å•ç­–ç•¥é€‰è‚¡ç»“æœ
        stg_select = pd.read_pickle(stg_select_result)
        if not stg_select.empty:
            # æ·»åŠ åˆ°æœ€ç»ˆé€‰è‚¡ç»“æœ
            all_select_df_list.append(stg_select)
            # è£åˆ‡æœ€æ–°é€‰è‚¡ç»“æœ
            logger.debug(f'ğŸ” è®¡ç®—`{strategy.name}`æœ€æ–°é€‰è‚¡ç»“æœ, æ•°æ®æœ€æ™šé€‰è‚¡æ—¥ï¼š{stg_select["é€‰è‚¡æ—¥æœŸ"].max()}')
            recent_select_df_list.append(stg_select[stg_select["é€‰è‚¡æ—¥æœŸ"] == stg_select["é€‰è‚¡æ—¥æœŸ"].max()])

    # åˆå¹¶æœ€ç»ˆé€‰è‚¡ç»“æœ
    if all_select_df_list:
        # èšåˆé€‰è‚¡ç»“æœ
        all_select_df = pd.concat(all_select_df_list, ignore_index=True, copy=False)
    else:
        all_select_df = pd.DataFrame(columns=RES_COLS)
    # åˆå¹¶æœ€æ–°é€‰è‚¡ç»“æœ
    if recent_select_df_list:
        recent_select_df = pd.concat(recent_select_df_list, ignore_index=True, copy=False)
    else:
        recent_select_df = pd.DataFrame(columns=RES_COLS)

    all_select_df = all_select_df.sort_values(by=["é€‰è‚¡æ—¥æœŸ", "æŒä»“å‘¨æœŸ", "é€‰è‚¡å› å­æ’å"])[RES_COLS].reset_index(
        drop=True
    )
    all_select_df.to_pickle(conf.select_results_path)
    # ä¿å­˜ä¸€ä»½ç»™ä½ æ ¸å¯¹ç»“æœç”¨ğŸ˜ƒ
    all_select_df.to_csv(conf.select_results_path.with_suffix(".csv"), encoding="utf-8-sig", index=False)
    # å†é™„èµ ä¸€ä»½æœ€æ–°é€‰è‚¡ç»“æœ
    recent_select_df = recent_select_df.sort_values(by=["é€‰è‚¡æ—¥æœŸ", "æŒä»“å‘¨æœŸ", "é€‰è‚¡å› å­æ’å"])[RES_COLS]
    recent_select_df.to_csv(result_folder / "æœ€æ–°é€‰è‚¡ç»“æœ.csv", encoding="utf-8-sig", index=False)

    return all_select_df


# ================================================================
# step4_å®ç›˜æ¨¡æ‹Ÿ.py
# ================================================================
def agg_ratios_by_period(conf: BacktestConfig, select_results: pd.DataFrame):
    s_time = time.time()

    logger.debug("ğŸ”€ æŒä»“å‘¨æœŸæƒé‡èšåˆ...")
    symbols = sorted(select_results["è‚¡ç¥¨ä»£ç "].unique())
    period_ratio_df = {}
    for (period, reb_time), grp_df in select_results.groupby(["æŒä»“å‘¨æœŸ", "æ¢ä»“æ—¶é—´"]):
        pivot_table_df = grp_df.pivot_table(
            index="é€‰è‚¡æ—¥æœŸ", columns="è‚¡ç¥¨ä»£ç ", values="ç›®æ ‡èµ„é‡‘å æ¯”", aggfunc="sum", fill_value=0
        )
        period_ratio_df[(period, reb_time)] = pivot_table_df

    logger.debug(f"ğŸ‘Œ æƒé‡èšåˆå®Œæˆï¼Œè€—æ—¶ï¼š{time.time() - s_time:.3f}ç§’")

    # é˜²å¾¡æ€§ç¼–ç¨‹
    if len(period_ratio_df) == 0:
        logger.critical("æƒé‡èšåˆç»“æœä¸ºç©ºï¼Œè¯·æ£€æŸ¥é€‰è‚¡ç»“æœ")
        logger.debug("âï¸ é€€å‡ºè¯•ç›˜æ¨¡æ‹Ÿï¼Œå› ä¸ºé€‰è‚¡ç»“æœä¸ºç©º")
        sys.exit()

    # ====================================================================================================
    # 2. å¯¹æ•°æ®è¿›è¡Œå¤„ç†
    # ====================================================================================================
    min_ratio_dt = min(ratio_df.index.min() for ratio_df in period_ratio_df.values()).date()
    min_ratio_date_str = min_ratio_dt.strftime("%Y-%m-%d")

    max_ratio_dt = max(ratio_df.index.max() for ratio_df in period_ratio_df.values()).date()
    max_ratio_date_str = max_ratio_dt.strftime("%Y-%m-%d")

    # ç¡®å®šå›æµ‹åŒºé—´
    conf.start_date = max(conf.start_date, min_ratio_date_str)
    conf.end_date = min(conf.end_date or max_ratio_date_str, max_ratio_date_str)
    logger.debug(f"ğŸ—“ï¸ å›æµ‹åŒºé—´:{conf.start_date}~{conf.end_date}")

    period_offset = conf.load_period_offset()

    # å¯¹äºäº¤æ˜“æ—¥å¯èƒ½ä¸ºç©ºçš„å‘¨æœŸè¿›è¡Œé‡æ–°å¡«å……
    for (period, reb_time), df_stock_ratio in period_ratio_df.items():
        rebalance_dates = period_offset.groupby(period)["äº¤æ˜“æ—¥æœŸ"].last()
        # å¯¹äºäº¤æ˜“æ—¥å¯èƒ½ä¸ºç©ºçš„å‘¨æœŸè¿›è¡Œé‡æ–°å¡«å……ï¼Œä¸å­˜åœ¨çš„ symbol å¡«å…… ratio ä¸º 0
        period_ratio_df[(period, reb_time)] = df_stock_ratio.reindex(
            index=rebalance_dates, columns=symbols, fill_value=0
        ).sort_index()

    pd.to_pickle(period_ratio_df, conf.get_result_folder() / "period_ratio_df.pkl")
    backtest_days = (max_ratio_dt - min_ratio_dt).days
    logger.info(f"éœ€è¦å›æº¯ {backtest_days:,} å¤©...")
    return period_ratio_df
