"""
é‚¢ä¸è¡Œï½œç­–ç•¥åˆ†äº«ä¼š
è‚¡ç¥¨é‡åŒ–ç­–ç•¥æ¡†æ¶ğ“Ÿğ“»ğ“¸

ç‰ˆæƒæ‰€æœ‰ Â©ï¸ é‚¢ä¸è¡Œ
å¾®ä¿¡: xbx1717

æœ¬ä»£ç ä»…ä¾›ä¸ªäººå­¦ä¹ ä½¿ç”¨ï¼Œæœªç»æˆæƒä¸å¾—å¤åˆ¶ã€ä¿®æ”¹æˆ–ç”¨äºå•†ä¸šç”¨é€”ã€‚

Author: é‚¢ä¸è¡Œ
"""

from pathlib import Path

import numpy as np
import pandas as pd

from config import data_center_path
from core.utils.log_kit import logger

data_center_path = Path(data_center_path)


def auto_load_data(file_path: str | Path, candle_df: pd.DataFrame, save_cols: list):
    """æ ¹æ®æ•°æ®åï¼Œè‡ªåŠ¨åŠ è½½æ•°æ®"""
    return _load_normal_data(file_path, candle_df, save_cols)


def _load_normal_data(file_path: str, candle_df: pd.DataFrame, save_cols: list):
    # ä¸ªè‚¡è‚¡ç¥¨ä»£ç 
    code = candle_df["è‚¡ç¥¨ä»£ç "].iloc[0]
    # ä¸ªè‚¡åˆ†é’Ÿæ•°æ®è·¯å¾„
    path = Path(file_path) / (code + ".csv")
    new_save_cols = [col for col in save_cols if col not in candle_df.columns]
    if path.exists():
        min_data = pd.read_csv(
            path, encoding="gbk", parse_dates=["äº¤æ˜“æ—¥æœŸ"], skiprows=1, usecols=["äº¤æ˜“æ—¥æœŸ", "è‚¡ç¥¨ä»£ç "] + new_save_cols
        )
        candle_df = pd.merge(candle_df, min_data, on=["äº¤æ˜“æ—¥æœŸ", "è‚¡ç¥¨ä»£ç "], how="left")
    else:
        for col in new_save_cols:
            candle_df[col] = np.nan
    return candle_df


def load_hk_stock(file_path: str, candle_df: pd.DataFrame, save_cols: list) -> pd.DataFrame | None:
    hkd_cny_path = data_center_path / "stock-cny-rate" / "HKD_CNY_rate.csv"
    if not hkd_cny_path.exists():
        logger.error(f"æ¸¯è‚¡æ•°æ®ä¾èµ–æ¸¯å…ƒæ±‡ç‡æ•°æ®ï¼š{hkd_cny_path}ï¼Œè¯·åœ¨æ•°æ®ä¸­å¿ƒè®¢é˜…â€œCNYæ±‡ç‡æ•°æ®â€åé‡è¯•")
        raise FileNotFoundError

    hkd_cny = pd.read_csv(hkd_cny_path, encoding="gbk", skiprows=1, parse_dates=["æ—¥æœŸ"])
    # ä¸ªè‚¡è‚¡ç¥¨ä»£ç 
    code = candle_df["è‚¡ç¥¨ä»£ç "].iloc[0]
    # æ¸¯è‚¡ä¸ªè‚¡æ•°æ®è·¯å¾„
    hk_stock_path = Path(file_path) / (code + "_HK.csv")
    # å¦‚æœå¯ä»¥æ‰¾åˆ°è¿™ä¸ªæ¸¯è‚¡çš„ä¸ªè‚¡æ•°æ®
    if hk_stock_path.exists():
        # è¯»å–æ¸¯è‚¡ä¸ªè‚¡æ•°æ®
        hk_df = pd.read_csv(
            hk_stock_path,
            encoding="gbk",
            parse_dates=["äº¤æ˜“æ—¥æœŸ"],
            usecols=["äº¤æ˜“æ—¥æœŸ", "æ”¶ç›˜ä»·", "å‰æ”¶ç›˜ä»·"],
            skiprows=1,
        )
        hk_df["æ”¶ç›˜ä»·"] = hk_df["æ”¶ç›˜ä»·"].ffill()
        hk_df["å‰æ”¶ç›˜ä»·"] = hk_df["å‰æ”¶ç›˜ä»·"].ffill()
        # è®¡ç®—å¤æƒå› å­
        hk_df["å¤æƒå› å­"] = (hk_df["æ”¶ç›˜ä»·"] / hk_df["å‰æ”¶ç›˜ä»·"]).cumprod()
        # è®¡ç®—å‰å¤æƒã€åå¤æƒæ”¶ç›˜ä»·
        hk_df["æ”¶ç›˜ä»·_å¤æƒ"] = hk_df["å¤æƒå› å­"] * (hk_df.iloc[0]["æ”¶ç›˜ä»·"] / hk_df.iloc[0]["å¤æƒå› å­"])

        # åˆå¹¶è¯¥è‚¡ç¥¨çš„Aè‚¡å’Œæ¸¯è‚¡æ•°æ®
        temp = pd.merge_ordered(
            hk_df.rename(columns={"äº¤æ˜“æ—¥æœŸ": "äº¤æ˜“æ—¥æœŸ_æ¸¯è‚¡"}),
            candle_df,
            left_on="äº¤æ˜“æ—¥æœŸ_æ¸¯è‚¡",
            right_on="äº¤æ˜“æ—¥æœŸ",
            fill_method="ffill",
            suffixes=("_æ¸¯è‚¡", ""),
        )

        temp.dropna(subset=["äº¤æ˜“æ—¥æœŸ"], inplace=True)
        # æŒ‰ç…§äº¤æ˜“æ—¥æœŸåˆ—ä½œä¸ºsubsetï¼Œé‡åˆ°é‡å¤çš„æ—¥æœŸï¼Œä¿ç•™æœ€æ–°çš„æ•°æ®
        temp = temp.drop_duplicates(subset="äº¤æ˜“æ—¥æœŸ", keep="last")

        # åˆ¤æ–­è¯¥è‚¡ç¥¨åœ¨æ¸¯è‚¡æ˜¯ä¸æ˜¯å·²ç»é€€å¸‚ï¼šå¦‚æœAè‚¡å’Œæ¸¯è‚¡çš„æœ€æ–°äº¤æ˜“æ—¥æœŸç›¸å·®10å¤©ä»¥ä¸Šï¼Œå°±è®¤ä¸ºè¯¥è‚¡ç¥¨å·²ç»é€€å¸‚
        if (temp["äº¤æ˜“æ—¥æœŸ"].iloc[-1] - temp["äº¤æ˜“æ—¥æœŸ_æ¸¯è‚¡"].iloc[-1]).days > 10:
            # è·å–hk_dfæœ€æ–°çš„äº¤æ˜“æ—¥æœŸï¼Œå°†dataé‡Œçš„æ”¶ç›˜ä»·_æ¸¯è‚¡è¶…è¿‡è¿™ä¸ªæ—¥æœŸçš„æ•°æ®èµ‹å€¼ä¸ºnan
            last_date = hk_df["äº¤æ˜“æ—¥æœŸ"].iloc[-1]
            temp.loc[temp["äº¤æ˜“æ—¥æœŸ"] > last_date, "æ”¶ç›˜ä»·_æ¸¯è‚¡"] = pd.NA

        # åˆ é™¤æ¸¯è‚¡äº¤æ˜“æ—¥æœŸåˆ—
        temp.drop(columns=["äº¤æ˜“æ—¥æœŸ_æ¸¯è‚¡"], inplace=True)

        # åˆå¹¶è‚¡ç¥¨æ•°æ®å’Œæ±‡ç‡æ•°æ®
        temp = pd.merge_ordered(
            left=temp,
            right=hkd_cny[["æ—¥æœŸ", "æ”¶ç›˜ä»·"]],
            left_on="äº¤æ˜“æ—¥æœŸ",
            right_on="æ—¥æœŸ",
            fill_method="ffill",
            suffixes=("", "_æ±‡ç‡"),
        )
        temp.dropna(subset=["äº¤æ˜“æ—¥æœŸ"], inplace=True)
        # æŒ‰ç…§äº¤æ˜“æ—¥æœŸåˆ—ä½œä¸ºsubsetï¼Œé‡åˆ°é‡å¤çš„æ—¥æœŸï¼Œä¿ç•™æœ€æ–°çš„æ•°æ®
        temp = temp.drop_duplicates(subset="äº¤æ˜“æ—¥æœŸ", keep="last")
        # åˆ é™¤æ±‡ç‡äº¤æ˜“æ—¥æœŸåˆ—
        temp.drop(columns=["æ—¥æœŸ"], inplace=True)

        candle_df = pd.merge(
            candle_df, temp[["äº¤æ˜“æ—¥æœŸ", "æ”¶ç›˜ä»·_æ¸¯è‚¡", "æ”¶ç›˜ä»·_æ±‡ç‡", "æ”¶ç›˜ä»·_å¤æƒ_æ¸¯è‚¡"]], on="äº¤æ˜“æ—¥æœŸ", how="left"
        )

    # æ‰¾ä¸åˆ°ä¸ªè‚¡æ•°æ®ï¼Œå°±ç»™ä¸ªnanå€¼
    else:
        candle_df["æ”¶ç›˜ä»·_æ¸¯è‚¡"] = np.nan
        candle_df["æ”¶ç›˜ä»·_æ±‡ç‡"] = np.nan
        candle_df["æ”¶ç›˜ä»·_å¤æƒ_æ¸¯è‚¡"] = np.nan
    return candle_df


def load_dividend_delivery(file_path: str, candle_df: pd.DataFrame, save_cols: list):
    # ä¸ªè‚¡è‚¡ç¥¨ä»£ç 
    code = candle_df["è‚¡ç¥¨ä»£ç "].iloc[0]
    # ä¸ªè‚¡åˆ†çº¢æ•°æ®è·¯å¾„
    path = Path(file_path) / (code + ".csv")

    keep_cols = [
        "è¿‘ä¸€å¹´åˆ†çº¢",
        "åˆ†çº¢ç‡_ç™»è®°æ—¥",
        "åˆ†çº¢ç‡_ç™»è®°æ—¥_è¿‘å¹´å‡å€¼",
        "åˆ†çº¢ç‡_ç™»è®°æ—¥_è¿‘å¹´æ ‡å‡†å·®",
        "åˆ†çº¢ç‡_ç™»è®°æ—¥_è¿‘å¹´æ¬¡æ•°",
        "è¿ç»­åˆ†çº¢å¹´ä»½",
    ]

    if path.exists():
        # è¯»å–åˆ†çº¢æ•°æ®
        dividend_data = pd.read_csv(path, encoding="gbk", skiprows=1, parse_dates=["è‚¡æƒç™»è®°æ—¥", "æŠ¥å‘ŠæœŸ"])
        # è‚¡æƒç™»è®°æ—¥ä¸€å®šæ˜¯äº¤æ˜“æ—¥æœŸï¼Œä¸ºäº†mergeæ–¹ä¾¿ï¼Œç›´æ¥é‡å‘½å
        dividend_data.rename(columns={"è‚¡æƒç™»è®°æ—¥": "äº¤æ˜“æ—¥æœŸ"}, inplace=True)
        # åˆ é™¤ç›¸åŒäº¤æ˜“æ—¥çš„æ•°æ®ï¼Œä¿ç•™æœ€æ–°çš„
        dividend_data = dividend_data.drop_duplicates(subset=["äº¤æ˜“æ—¥æœŸ"], keep="last")
        # æŠŠæ”¶ç›˜ä»·æ•°æ®æ‹¿è¿‡æ¥
        dividend_data = pd.merge(dividend_data, candle_df[["äº¤æ˜“æ—¥æœŸ", "æ”¶ç›˜ä»·"]], on="äº¤æ˜“æ—¥æœŸ", how="left")
        # è®¡ç®—åˆ†çº¢ç‡
        dividend_data["åˆ†çº¢ç‡_ç™»è®°æ—¥"] = dividend_data["è¿‘ä¸€å¹´åˆ†çº¢"] / dividend_data["æ”¶ç›˜ä»·"]
        # è®¡ç®—ç™»è®°æ—¥çš„å¹´ä»½
        dividend_data["å¹´ä»½"] = dividend_data["æŠ¥å‘ŠæœŸ"].dt.year

        # è®¡ç®—æœ€è¿‘3å¹´çš„åˆ†çº¢çŠ¶æ€
        for i in dividend_data.index:
            hist_report_date = dividend_data.loc[i, "æŠ¥å‘ŠæœŸ"] - pd.DateOffset(years=3)
            temp_hist = dividend_data[
                (dividend_data["æŠ¥å‘ŠæœŸ"] > hist_report_date)
                & (dividend_data["æŠ¥å‘ŠæœŸ"] <= dividend_data.loc[i, "æŠ¥å‘ŠæœŸ"])
            ]
            dividend_data.loc[i, "åˆ†çº¢ç‡_ç™»è®°æ—¥_è¿‘å¹´å‡å€¼"] = temp_hist["åˆ†çº¢ç‡_ç™»è®°æ—¥"].mean()
            dividend_data.loc[i, "åˆ†çº¢ç‡_ç™»è®°æ—¥_è¿‘å¹´æ ‡å‡†å·®"] = temp_hist["åˆ†çº¢ç‡_ç™»è®°æ—¥"].std()
            dividend_data.loc[i, "åˆ†çº¢ç‡_ç™»è®°æ—¥_è¿‘å¹´æ¬¡æ•°"] = temp_hist["åˆ†çº¢ç‡_ç™»è®°æ—¥"].count()

            # è®¡ç®—è¿ç»­å¤šå°‘å¹´åˆ†çº¢
            temp_hist = dividend_data[: i + 1].copy()  # è·å–è‡³ä»Šçš„æ‰€æœ‰æ•°æ®
            dividend_years = list(set(temp_hist["å¹´ä»½"]))  # æœ‰äº›å¹´ä»½ä¼šåˆ†å¥½å‡ æ¬¡
            year_range = list(range(dividend_data.loc[i, "æŠ¥å‘ŠæœŸ"].year, temp_hist["æŠ¥å‘ŠæœŸ"].min().year - 1, -1))
            j = 0
            for year in year_range:
                if year in dividend_years:
                    j += 1
                else:
                    break
            dividend_data.loc[i, "è¿ç»­åˆ†çº¢å¹´ä»½"] = j

        # å°†åˆ†çº¢æ•°æ®ä¸æ—¥çº¿æ•°æ®å’Œè´¢åŠ¡æ•°æ®åˆå¹¶
        temp = pd.merge(
            left=candle_df[["äº¤æ˜“æ—¥æœŸ", "æ”¶ç›˜ä»·"]],
            right=dividend_data[["äº¤æ˜“æ—¥æœŸ"] + keep_cols],
            on=["äº¤æ˜“æ—¥æœŸ"],
            how="left",
        )

        # æŒ‰ç…§æœ€æ–°äº¤æ˜“æ—¥æœŸè®¡ç®—åˆ†çº¢
        # temp["è¿‘ä¸€å¹´åˆ†çº¢"].fillna(method="ffill", inplace=True)
        temp["è¿‘ä¸€å¹´åˆ†çº¢"] = temp["è¿‘ä¸€å¹´åˆ†çº¢"].ffill()
        temp["åˆ†çº¢ç‡_æœ€è¿‘æ—¥"] = temp["è¿‘ä¸€å¹´åˆ†çº¢"] / temp["æ”¶ç›˜ä»·"]
        keep_cols.append("åˆ†çº¢ç‡_æœ€è¿‘æ—¥")

        # ===åˆ†çº¢æ•°æ®åªä¿ç•™270ä¸ªäº¤æ˜“æ—¥ï¼Œå¦‚æœ270æ—¥ä»¥åè¿˜æ²¡æœ‰åˆ†çº¢æ•°æ®ï¼Œåˆ¤å®šå…¬å¸ä¸‹ä¸€å¹´ä¸åˆ†çº¢äº†ï¼Œå°†åˆ†çº¢æ•°æ®ä¿®æ­£ä¸ºnan
        mark_index = temp[~pd.isnull(temp["åˆ†çº¢ç‡_ç™»è®°æ—¥"])].index
        index_list = []
        for index in mark_index:
            index_list += list(range(index, index + 271))
        # index_listå¯èƒ½æœ‰é‡å¤å€¼ï¼Œå»é‡
        index_list = list(set(index_list))
        # å…ˆå¡«å……ï¼Œå†èµ‹nan
        # temp.fillna(method="ffill", inplace=True)
        temp = temp.ffill()
        # index_listä»¥å¤–çš„æ•°æ®ï¼Œåˆ†çº¢æ•°æ®ä¿®æ­£ä¸ºnan
        temp.loc[~temp.index.isin(index_list), keep_cols] = np.nan

        # å°†åˆ†çº¢æ•°æ®ä¸æ—¥çº¿æ•°æ®å’Œè´¢åŠ¡æ•°æ®åˆå¹¶
        candle_df = pd.merge(candle_df, temp[["äº¤æ˜“æ—¥æœŸ"] + keep_cols], on="äº¤æ˜“æ—¥æœŸ", how="left")

    else:
        # æ²¡æœ‰åˆ†çº¢æ•°æ®ï¼Œç”¨ç©ºå€¼ä»£æ›¿
        keep_cols.append("åˆ†çº¢ç‡_æœ€è¿‘æ—¥")
        for col in keep_cols:
            candle_df[col] = np.nan

    return candle_df


def load_15min_data(file_path: str | Path, candle_df: pd.DataFrame, save_cols: list):
    # fmt: off
    save_cols = save_cols or ['0930', '0945', '1000', '1015', '1030', '1045', '1100', '1115', '1130',
                              '1315', '1330', '1345', '1400', '1415', '1430', '1445']
    # fmt: on
    return _load_normal_data(file_path, candle_df, save_cols)


def load_5min_data(file_path: str | Path, candle_df: pd.DataFrame, save_cols: list):
    # fmt: off
    save_cols = save_cols or [
        '0930', '0935', '0940', '0945', '0950', '0955',
        '1000', '1005', '1010', '1015', '1020', '1025', '1030', '1035', '1040', '1045', '1050', '1055',
        '1100', '1105', '1110', '1115', '1120', '1125', '1130',
        '1305', '1310', '1315', '1320', '1325', '1330', '1335', '1340', '1345', '1350', '1355',
        '1400', '1405', '1410', '1415', '1420', '1425', '1430', '1435', '1440', '1445', '1450', '1455'
    ]
    # fmt: on
    return _load_normal_data(file_path, candle_df, save_cols)


def load_stock_notices_title(file_path: str | Path, candle_df: pd.DataFrame, save_cols: list):
    # ä¸ªè‚¡è‚¡ç¥¨ä»£ç 
    code = candle_df.at[0, "è‚¡ç¥¨ä»£ç "]
    # æ•°æ®è·¯å¾„
    path = Path(file_path) / (code + ".csv")
    new_save_cols = [col for col in save_cols if col not in candle_df.columns]
    if path.exists():
        notices_data = pd.read_csv(
            path, encoding="gbk", parse_dates=["å…¬å‘Šæ—¥æœŸ"], skiprows=1, usecols=["å…¬å‘Šæ—¥æœŸ", "è‚¡ç¥¨ä»£ç ", "å…¬å‘Šæ ‡é¢˜"]
        )
        merge_df = pd.merge_asof(
            notices_data, candle_df[["äº¤æ˜“æ—¥æœŸ"]], left_on="å…¬å‘Šæ—¥æœŸ", right_on="äº¤æ˜“æ—¥æœŸ", direction="backward"
        )
        agg_result = merge_df.groupby("äº¤æ˜“æ—¥æœŸ").agg({"å…¬å‘Šæ ‡é¢˜": lambda x: "==".join(x) if not x.empty else ""})
        agg_result["å…¬å‘Šæ•°é‡"] = merge_df.groupby("äº¤æ˜“æ—¥æœŸ").size()
        candle_df = pd.merge(candle_df, agg_result[["å…¬å‘Šæ ‡é¢˜", "å…¬å‘Šæ•°é‡"]], on="äº¤æ˜“æ—¥æœŸ", how="left").fillna(
            {"å…¬å‘Šæ ‡é¢˜": "", "å…¬å‘Šæ•°é‡": 0}
        )
    else:
        for col in new_save_cols:
            candle_df[col] = "" if col == "å…¬å‘Šæ ‡é¢˜" else np.nan
    return candle_df


presets = {
    # fmt: off
    # å˜é‡å‘½åä¹‹åéœ€è¦ç»Ÿä¸€ï¼Œ-æ”¹æˆ_ï¼Œå‰ä¸¤ä¸ªæ•°æ®æ¶‰åŠå¤ªå¹¿ï¼Œæš‚æ—¶å…ˆä¸æ”¹ï¼Œåç»­å…¨ç”¨_
    # AHæ¸¯è‚¡æ•°æ®ï¼ˆstock-hk-stock-dataï¼‰ï¼Œä¸‹è½½åœ°å€ï¼šhttps://www.quantclass.cn/data/stock/stock-hk-stock-data
    # ä½¿ç”¨æ¡ˆä¾‹ï¼šextra_data = {'hk-stock': ['æ”¶ç›˜ä»·_æ¸¯è‚¡', 'æ”¶ç›˜ä»·_æ±‡ç‡', 'æ”¶ç›˜ä»·_å¤æƒ_æ¸¯è‚¡']}
    "hk-stock": (load_hk_stock, Path(data_center_path) / "stock-hk-stock-data"),

    # ä¸ªè‚¡åˆ†çº¢æ•°æ®(stock-dividend-delivery)ï¼Œä¸‹è½½åœ°å€ï¼šhttps://www.quantclass.cn/data/stock/stock-dividend-delivery
    # ä½¿ç”¨æ¡ˆä¾‹ï¼šextra_data = {'dividend-delivery': ['è¿‘ä¸€å¹´åˆ†çº¢', 'åˆ†çº¢ç‡_ç™»è®°æ—¥', 'åˆ†çº¢ç‡_ç™»è®°æ—¥_è¿‘å¹´å‡å€¼', 'åˆ†çº¢ç‡_ç™»è®°æ—¥_è¿‘å¹´æ ‡å‡†å·®','åˆ†çº¢ç‡_ç™»è®°æ—¥_è¿‘å¹´æ¬¡æ•°', 'è¿ç»­åˆ†çº¢å¹´ä»½','åˆ†çº¢ç‡_æœ€è¿‘æ—¥']}
    "dividend-delivery": (load_dividend_delivery, Path(data_center_path) / "stock-dividend-delivery"),

    # è‚¡ç¥¨15åˆ†é’Ÿæ”¶ç›˜ä»·(stock-15m-close-price)ï¼Œä¸‹è½½åœ°å€ï¼šhttps://www.quantclass.cn/data/stock/stock-15m-close-price
    # ä½¿ç”¨æ¡ˆä¾‹ï¼šextra_data = {'15min_close': ['945', '1000', '1015', '1030', '1045', '1100', '1115', '1130', '1315', '1330', '1345', '1400', '1415', '1430', '1445']}
    "15min_close": (load_15min_data, Path(data_center_path) / "stock-15m-close-price"),

    # è‚¡ç¥¨5åˆ†é’Ÿæ”¶ç›˜ä»·(stock-5m-close-price)ï¼Œä¸‹è½½åœ°å€ï¼šhttps://www.quantclass.cn/data/stock/stock-5m-close-price
    # ä½¿ç”¨æ¡ˆä¾‹ï¼šextra_data = {'5min_close': ['935', '940', '945', '950', '955', '1000', '1005', '1010', '1015', '1020', '1025', '1030', '1035', '1040', '1045', '1050', '1055', '1100', '1105', '1110', '1115', '1120', '1125', '1130', '1305', '1310', '1315', '1320', '1325', '1330', '1335', '1340', '1345', '1350', '1355', '1400', '1405', '1410', '1415', '1420', '1425', '1430', '1435', '1440', '1445', '1450', '1455']}
    "5min_close": (load_5min_data, Path(data_center_path) / "stock-5m-close-price"),

    # ç­¹ç åˆ†å¸ƒå¸‚åœºæ•°æ®(stock-chip-distribution)ï¼Œä¸‹è½½åœ°å€ï¼šhttps://www.quantclass.cn/data/stock/stock-chip-distribution
    # ä½¿ç”¨æ¡ˆä¾‹ï¼šextra_data = {'stock_chip_distribution': ['åå¤æƒä»·æ ¼', 'å†å²æœ€ä½ä»·', 'å†å²æœ€é«˜ä»·', '5åˆ†ä½æˆæœ¬', '10åˆ†ä½æˆæœ¬', '15åˆ†ä½æˆæœ¬', '20åˆ†ä½æˆæœ¬', '25åˆ†ä½æˆæœ¬', '30åˆ†ä½æˆæœ¬', '35åˆ†ä½æˆæœ¬', '40åˆ†ä½æˆæœ¬', '45åˆ†ä½æˆæœ¬', '50åˆ†ä½æˆæœ¬', '55åˆ†ä½æˆæœ¬', '60åˆ†ä½æˆæœ¬', '65åˆ†ä½æˆæœ¬', '70åˆ†ä½æˆæœ¬', '75åˆ†ä½æˆæœ¬', '80åˆ†ä½æˆæœ¬', '85åˆ†ä½æˆæœ¬', '90åˆ†ä½æˆæœ¬', '95åˆ†ä½æˆæœ¬', 'åŠ æƒå¹³å‡æˆæœ¬', 'èƒœç‡']}
    "stock_chip_distribution": (auto_load_data, Path(data_center_path) / "stock-chip-distribution"),

    # æ‘†åŠ¨æŒ‡æ ‡å› å­(stock-oscillator-factors)ï¼Œä¸‹è½½åœ°å€ï¼šhttps://www.quantclass.cn/data/stock/stock-oscillator-factors
    # ä½¿ç”¨æ¡ˆä¾‹ï¼šextra_data = {'stock_oscillator_factors': ['coppock', 'coppock_5_è¡°å‡åŠ æƒ', 'coppock_20_è¡°å‡åŠ æƒ', 'SRMi', 'SRMi_5_è¡°å‡åŠ æƒ', 'SRMi_20_è¡°å‡åŠ æƒ']}
    "stock_oscillator_factors": (auto_load_data, Path(data_center_path) / "stock-oscillator-factors"),

    # æŠ€æœ¯æŒ‡æ ‡å› å­(stock-technical-factors)ï¼Œä¸‹è½½åœ°å€ï¼šhttps://www.quantclass.cn/data/stock/stock-technical-factors
    # ä½¿ç”¨æ¡ˆä¾‹ï¼šextra_data = {'stock_technical_factors': ['ATR', 'ATR_5_è¡°å‡åŠ æƒ', 'ATR_20_è¡°å‡åŠ æƒ']}
    "stock_technical_factors": (auto_load_data, Path(data_center_path) / "stock-technical-factors"),

    # åè¶‹å‘æŒ‡æ ‡å› å­(stock-anti-trend-factors)ï¼Œä¸‹è½½åœ°å€ï¼šhttps://www.quantclass.cn/data/stock/stock-anti-trend-factors
    # ä½¿ç”¨æ¡ˆä¾‹ï¼šextra_data = {'stock_anti_trend_factors': ['Bias_min', 'Bias_min_5_è¡°å‡åŠ æƒ', 'Bias_min_20_è¡°å‡åŠ æƒ', 'CCI', 'CCI_5_è¡°å‡åŠ æƒ', 'CCI_20_è¡°å‡åŠ æƒ', 'RSI', 'RSI_5_è¡°å‡åŠ æƒ', 'RSI_20_è¡°å‡åŠ æƒ']}
    "stock_anti_trend_factors": (auto_load_data, Path(data_center_path) / "stock-anti-trend-factors"),

    # é‡ä»·æŒ‡æ ‡å› å­(stock-volume-price-factors)ï¼Œä¸‹è½½åœ°å€ï¼šhttps://www.quantclass.cn/data/stock/stock-volume-price-factors
    # ä½¿ç”¨æ¡ˆä¾‹ï¼šextra_data = {'stock_volume_price_factors': ['EOM', 'EOM_5_è¡°å‡åŠ æƒ', 'EOM_20_è¡°å‡åŠ æƒ', 'Money_Flow', 'Money_Flow_5_è¡°å‡åŠ æƒ', 'Money_Flow_20_è¡°å‡åŠ æƒ', 'PVT', 'PVT_5_è¡°å‡åŠ æƒ', 'PVT_20_è¡°å‡åŠ æƒ']}
    "stock_volume_price_factors": (auto_load_data, Path(data_center_path) / "stock-volume-price-factors"),

    # èƒ½é‡æŒ‡æ ‡å› å­(stock-energy-factors)ï¼Œä¸‹è½½åœ°å€ï¼šhttps://www.quantclass.cn/data/stock/stock-energy-factors
    # ä½¿ç”¨æ¡ˆä¾‹ï¼šextra_data = {'stock_energy_factors': ['VRæˆäº¤é‡æ¯”ç‡', 'VRæˆäº¤é‡æ¯”ç‡_5_è¡°å‡åŠ æƒ', 'VRæˆäº¤é‡æ¯”ç‡_20_è¡°å‡åŠ æƒ', 'äººæ°”æŒ‡æ ‡BR', 'äººæ°”æŒ‡æ ‡BR_5_è¡°å‡åŠ æƒ', 'äººæ°”æŒ‡æ ‡BR_20_è¡°å‡åŠ æƒ', 'ä¸­é—´æ„æ„¿æŒ‡æ ‡CR', 'ä¸­é—´æ„æ„¿æŒ‡æ ‡CR_5_è¡°å‡åŠ æƒ', 'ä¸­é—´æ„æ„¿æŒ‡æ ‡CR_20_è¡°å‡åŠ æƒ']}
    "stock_energy_factors": (auto_load_data, Path(data_center_path) / "stock-energy-factors"),

    # è¶‹å‘æŒ‡æ ‡å› å­(stock-trend-factors)ï¼Œä¸‹è½½åœ°å€ï¼šhttps://www.quantclass.cn/data/stock/stock-trend-factors
    # ä½¿ç”¨æ¡ˆä¾‹ï¼šextra_data = {'stock_trend_factors': ['MACD', 'MACD_5_è¡°å‡åŠ æƒ', 'MACD_20_è¡°å‡åŠ æƒ', 'MTM_ma', 'MTM_ma_5_è¡°å‡åŠ æƒ', 'MTM_ma_20_è¡°å‡åŠ æƒ', 'æ”¶é›†æ´¾å‘_ACD', 'æ”¶é›†æ´¾å‘_ACD_5_è¡°å‡åŠ æƒ', 'æ”¶é›†æ´¾å‘_ACD_20_è¡°å‡åŠ æƒ']}
    "stock_trend_factors": (auto_load_data, Path(data_center_path) / "stock-trend-factors"),

    # å¤šå› å­ç³»åˆ—(stock-multi-factor-series)ï¼Œä¸‹è½½åœ°å€ï¼šhttps://www.quantclass.cn/data/stock/stock-multi-factor-series
    # ä½¿ç”¨æ¡ˆä¾‹ï¼šextra_data = {'stock_multi_factor_series': ['æ½®æ±å› å­_å¼ºåŠ¿åŠæ½®æ±', 'é€‚åº¦å†’é™©', 'é€‚åº¦å†’é™©_æœˆè€€çœ¼æ³¢åŠ¨ç‡', 'å‹‡æ”€é«˜å³°_æœˆç¨³æ”€ç™»', 'äº‘å¼€é›¾æ•£_æœˆå‡æ¨¡ç³Šå…³è”åº¦', 'äº‘å¼€é›¾æ•£_æ¨¡ç³Šå…³è”åº¦']}
    "stock_multi_factor_series": (auto_load_data, Path(data_center_path) / "stock-multi-factor-series"),

    # è‚¡ç¥¨å…¬å‘Šæ ‡é¢˜æ±‡æ€»(stock-notices-title)ï¼Œä¸‹è½½åœ°å€ï¼šhttps://www.quantclass.cn/data/stock/stock-notices-title
    # ä½¿ç”¨æ¡ˆä¾‹ï¼šextra_data = {'stock_notices_title': ['å…¬å‘Šæ ‡é¢˜','å…¬å‘Šæ•°é‡']}
    "stock_notices_title": (load_stock_notices_title, Path(data_center_path) / "stock-notices-title"),
    # fmt: on
}
