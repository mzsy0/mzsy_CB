"""
é‚¢ä¸è¡Œï½œç­–ç•¥åˆ†äº«ä¼š
è‚¡ç¥¨é‡åŒ–ç­–ç•¥æ¡†æ¶ğ“Ÿğ“»ğ“¸

ç‰ˆæƒæ‰€æœ‰ Â©ï¸ é‚¢ä¸è¡Œ
å¾®ä¿¡: xbx1717

æœ¬ä»£ç ä»…ä¾›ä¸ªäººå­¦ä¹ ä½¿ç”¨ï¼Œæœªç»æˆæƒä¸å¾—å¤åˆ¶ã€ä¿®æ”¹æˆ–ç”¨äºå•†ä¸šç”¨é€”ã€‚

Author: é‚¢ä¸è¡Œ
"""

import hashlib
import os
import time
import traceback
from decimal import ROUND_UP
from pathlib import Path

import numpy as np
import pandas as pd
import requests
from sklearn.linear_model import LinearRegression

from core.utils.log_kit import logger

pd.set_option("expand_frame_repr", False)
pd.set_option("future.no_silent_downcasting", True)
# printè¾“å‡ºä¸­æ–‡è¡¨å¤´å¯¹é½
pd.set_option("display.unicode.ambiguous_as_wide", True)
pd.set_option("display.unicode.east_asian_width", True)


def cal_fuquan_price(df, fuquan_type="åå¤æƒ", method=None):
    """
    ç”¨äºè®¡ç®—å¤æƒä»·æ ¼

    å‚æ•°:
    df (DataFrame): å¿…é¡»åŒ…å«çš„å­—æ®µï¼šæ”¶ç›˜ä»·ï¼Œå‰æ”¶ç›˜ä»·ï¼Œå¼€ç›˜ä»·ï¼Œæœ€é«˜ä»·ï¼Œæœ€ä½ä»·
    fuquan_type (str, optional): å¤æƒç±»å‹ï¼Œå¯é€‰å€¼ä¸º 'å‰å¤æƒ' æˆ– 'åå¤æƒ'ï¼Œé»˜è®¤ä¸º 'åå¤æƒ'
    method (str, optional): é¢å¤–è®¡ç®—å¤æƒä»·æ ¼çš„æ–¹æ³•ï¼Œå¦‚ 'å¼€ç›˜'ï¼Œé»˜è®¤ä¸º None

    è¿”å›:
    DataFrame: æœ€ç»ˆè¾“å‡ºçš„dfä¸­ï¼Œæ–°å¢å­—æ®µï¼šæ”¶ç›˜ä»·_å¤æƒï¼Œå¼€ç›˜ä»·_å¤æƒï¼Œæœ€é«˜ä»·_å¤æƒï¼Œæœ€ä½ä»·_å¤æƒ
    """

    # è®¡ç®—å¤æƒå› å­
    fq_factor = (df["æ”¶ç›˜ä»·"] / df["å‰æ”¶ç›˜ä»·"]).cumprod()

    # è®¡ç®—å‰å¤æƒæˆ–åå¤æƒæ”¶ç›˜ä»·
    if fuquan_type == "åå¤æƒ":  # å¦‚æœä½¿ç”¨åå¤æƒæ–¹æ³•
        fq_close = fq_factor * (df.iloc[0]["æ”¶ç›˜ä»·"] / fq_factor.iloc[0])
    elif fuquan_type == "å‰å¤æƒ":  # å¦‚æœä½¿ç”¨å‰å¤æƒæ–¹æ³•
        fq_close = fq_factor * (df.iloc[-1]["æ”¶ç›˜ä»·"] / fq_factor.iloc[-1])
    else:  # å¦‚æœç»™çš„å¤æƒæ–¹æ³•éä¸Šè¿°ä¸¤ç§æ ‡å‡†æ–¹æ³•ä¼šæŠ¥é”™
        raise ValueError(f"è®¡ç®—å¤æƒä»·æ—¶ï¼Œå‡ºç°æœªçŸ¥çš„å¤æƒç±»å‹ï¼š{fuquan_type}")

    # è®¡ç®—å…¶ä»–ä»·æ ¼çš„å¤æƒå€¼
    fq_open = df["å¼€ç›˜ä»·"] / df["æ”¶ç›˜ä»·"] * fq_close
    fq_high = df["æœ€é«˜ä»·"] / df["æ”¶ç›˜ä»·"] * fq_close
    fq_low = df["æœ€ä½ä»·"] / df["æ”¶ç›˜ä»·"] * fq_close

    # ä¸€æ¬¡æ€§èµ‹å€¼ï¼Œæé«˜è®¡ç®—æ•ˆç‡
    df = df.assign(
        å¤æƒå› å­=fq_factor, æ”¶ç›˜ä»·_å¤æƒ=fq_close, å¼€ç›˜ä»·_å¤æƒ=fq_open, æœ€é«˜ä»·_å¤æƒ=fq_high, æœ€ä½ä»·_å¤æƒ=fq_low
    )

    # å¦‚æœæŒ‡å®šäº†é¢å¤–çš„æ–¹æ³•ï¼Œè®¡ç®—è¯¥æ–¹æ³•çš„å¤æƒä»·æ ¼
    if method and method != "å¼€ç›˜":
        df[f"{method}_å¤æƒ"] = df[method] / df["æ”¶ç›˜ä»·"] * fq_close

    # åˆ é™¤ä¸­é—´å˜é‡å¤æƒå› å­
    # df.drop(columns=['å¤æƒå› å­'], inplace=True)

    return df


def get_file_in_folder(path, file_type, contains=None, filters=(), drop_type=False):
    """
    è·å–æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹çš„æ–‡ä»¶

    å‚æ•°:
    path (str): æ–‡ä»¶å¤¹è·¯å¾„
    file_type (str): æ–‡ä»¶ç±»å‹ï¼Œä¾‹å¦‚ '.csv' æˆ– '.txt'
    contains (str, optional): æ–‡ä»¶åä¸­éœ€è¦åŒ…å«çš„å­—ç¬¦ä¸²ï¼Œé»˜è®¤ä¸º None
    filters (list, optional): æ–‡ä»¶åä¸­éœ€è¦è¿‡æ»¤æ‰çš„å†…å®¹ï¼Œåˆ—è¡¨å½¢å¼ï¼Œé»˜è®¤ä¸ºç©ºåˆ—è¡¨
    drop_type (bool, optional): æ˜¯å¦è¦å»é™¤æ–‡ä»¶æ‰©å±•åï¼Œé»˜è®¤ä¸º False

    è¿”å›:
    list: ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶ååˆ—è¡¨
    """
    # è·å–æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å
    file_list = os.listdir(path)

    # è¿‡æ»¤å‡ºæŒ‡å®šç±»å‹çš„æ–‡ä»¶
    file_list = [file for file in file_list if file.endswith(file_type)]

    # å¦‚æœæŒ‡å®šäº†åŒ…å«çš„å­—ç¬¦ä¸²ï¼Œè¿›ä¸€æ­¥è¿‡æ»¤
    if contains:
        file_list = [file for file in file_list if contains in file]

    # è¿‡æ»¤æ‰æŒ‡å®šçš„å†…å®¹
    for con in filters:
        file_list = [file for file in file_list if con not in file]

    # å¦‚æœéœ€è¦å»é™¤æ–‡ä»¶æ‰©å±•å
    if drop_type:
        file_list = [file[: file.rfind(".")] for file in file_list]

    return file_list


def import_index_data(path, date_range=(None, None), max_param=0):
    """
    å¯¼å…¥æŒ‡æ•°æ•°æ®å¹¶è¿›è¡Œé¢„å¤„ç†

    å‚æ•°:
    path (str): æŒ‡æ•°æ•°æ®æ–‡ä»¶çš„è·¯å¾„
    date_range (list, optional): å›æµ‹çš„æ—¶é—´èŒƒå›´ï¼Œæ ¼å¼ä¸º [å¼€å§‹æ—¥æœŸ, ç»“æŸæ—¥æœŸ]ï¼Œé»˜è®¤ä¸º [None, None]
    max_param (int, optional): å› å­çš„æœ€å¤§å‘¨æœŸæ•°ï¼Œç”¨äºæ§åˆ¶å¼€å§‹æ—¥æœŸï¼Œç¡®ä¿rollingç±»å› å­ï¼Œå‰ç½®æ•°æ®ä¸æ˜¯NaNï¼Œé»˜è®¤ä¸º 0

    è¿”å›:
    DataFrame: å¤„ç†åçš„æŒ‡æ•°æ•°æ®ï¼ŒåŒ…å«äº¤æ˜“æ—¥æœŸå’ŒæŒ‡æ•°æ¶¨è·Œå¹…
    """
    # å¯¼å…¥æŒ‡æ•°æ•°æ®
    df_index = pd.read_csv(path, parse_dates=["candle_end_time"], encoding="gbk")

    # è®¡ç®—æ¶¨è·Œå¹…
    df_index["æŒ‡æ•°æ¶¨è·Œå¹…"] = df_index["close"].pct_change()
    # ç¬¬ä¸€å¤©çš„æŒ‡æ•°æ¶¨è·Œå¹…æ˜¯å¼€ç›˜ä¹°å…¥çš„æ¶¨è·Œå¹…
    df_index["æŒ‡æ•°æ¶¨è·Œå¹…"] = df_index["æŒ‡æ•°æ¶¨è·Œå¹…"].fillna(value=df_index["close"] / df_index["open"] - 1)

    # ä¿ç•™å¿…è¦çš„åˆ—
    df_index = df_index[["candle_end_time", "æŒ‡æ•°æ¶¨è·Œå¹…"]]

    # å»é™¤æ¶¨è·Œå¹…ä¸ºç©ºçš„è¡Œ
    df_index.dropna(subset=["æŒ‡æ•°æ¶¨è·Œå¹…"], inplace=True)

    # é‡å‘½ååˆ—
    df_index.rename(columns={"candle_end_time": "äº¤æ˜“æ—¥æœŸ"}, inplace=True)

    # æ ¹æ®æ—¥æœŸèŒƒå›´è¿‡æ»¤æ•°æ®
    if date_range[0]:
        if max_param == 0:
            df_index = df_index[df_index["äº¤æ˜“æ—¥æœŸ"] >= pd.to_datetime(date_range[0])]
            # print(f'ğŸ’¡ å›æµ‹å¼€å§‹æ—¶é—´ï¼š{df_index["äº¤æ˜“æ—¥æœŸ"].iloc[0].strftime("%Y-%m-%d")}')
        # å½“æä¾›äº†å‘¨æœŸæ•°ä¹‹å
        else:
            # è®¡ç®—æ–°çš„å¼€å§‹æ—¥æœŸ
            start_index = df_index[df_index["äº¤æ˜“æ—¥æœŸ"] >= pd.to_datetime(date_range[0])].index[0]
            start_date = df_index["äº¤æ˜“æ—¥æœŸ"][start_index].strftime("%Y-%m-%d")

            # ç§»åŠ¨å‘¨æœŸï¼Œè·å–å¯ä»¥è®©å› å­æ•°å€¼ä¸ä¸ºNançš„å¼€å§‹æ—¥æœŸ
            shifted_date = df_index["äº¤æ˜“æ—¥æœŸ"].shift(max_param)
            shifted_date.bfill(inplace=True)  # å‰ç½®æ•°æ®ä¸æ˜¯NaN

            # è¿‡æ»¤å‰ç½®æ•°æ®
            df_index = df_index[df_index["äº¤æ˜“æ—¥æœŸ"] >= shifted_date[start_index]]
            new_start_date = df_index["äº¤æ˜“æ—¥æœŸ"].iloc[0].strftime("%Y-%m-%d")
            print(f"ğŸ’¡ å›æµ‹å¼€å§‹æ—¶é—´ï¼š{start_date}ï¼Œç§»åŠ¨{max_param}ä¸ªå‘¨æœŸï¼Œæœ€æ–°äº¤æ˜“æ—¥ï¼š{new_start_date}")
    if date_range[1]:
        df_index = df_index[df_index["äº¤æ˜“æ—¥æœŸ"] <= pd.to_datetime(date_range[1])]
        # print(f'å›æµ‹ç»“æŸæ—¶é—´ï¼š{df_index["äº¤æ˜“æ—¥æœŸ"].iloc[-1].strftime("%Y-%m-%d")}')

    # æŒ‰æ—¶é—´æ’åºå¹¶é‡ç½®ç´¢å¼•
    df_index.sort_values(by=["äº¤æ˜“æ—¥æœŸ"], inplace=True)
    df_index.reset_index(inplace=True, drop=True)

    return df_index


def merge_with_index_data(df, index_data, fill_0_list=()):
    """
    åŸå§‹è‚¡ç¥¨æ•°æ®åœ¨ä¸äº¤æ˜“çš„æ—¶å€™æ²¡æœ‰æ•°æ®ã€‚
    å°†åŸå§‹è‚¡ç¥¨æ•°æ®å’ŒæŒ‡æ•°æ•°æ®åˆå¹¶ï¼Œå¯ä»¥è¡¥å…¨åŸå§‹è‚¡ç¥¨æ•°æ®æ²¡æœ‰äº¤æ˜“çš„æ—¥æœŸã€‚

    å‚æ•°:
    df (DataFrame): è‚¡ç¥¨æ•°æ®
    index_data (DataFrame): æŒ‡æ•°æ•°æ®
    extra_fill_0_list (list, optional): åˆå¹¶æ—¶éœ€è¦å¡«å……ä¸º0çš„å­—æ®µï¼Œé»˜è®¤ä¸ºç©ºåˆ—è¡¨

    è¿”å›:
    DataFrame: åˆå¹¶åçš„è‚¡ç¥¨æ•°æ®ï¼ŒåŒ…å«è¡¥å…¨çš„æ—¥æœŸ
    """
    max_candle_time = index_data["äº¤æ˜“æ—¥æœŸ"].max()
    # å°†è‚¡ç¥¨æ•°æ®å’ŒæŒ‡æ•°æ•°æ®åˆå¹¶ï¼Œç»“æœå·²ç»æ’åº
    df = pd.merge(
        left=df,
        right=index_data[index_data["äº¤æ˜“æ—¥æœŸ"] <= max_candle_time],
        on="äº¤æ˜“æ—¥æœŸ",
        how="right",
        sort=True,
        indicator=True,
    )

    # å¯¹å¼€ã€é«˜ã€æ”¶ã€ä½ã€å‰æ”¶ç›˜ä»·ä»·æ ¼è¿›è¡Œè¡¥å…¨å¤„ç†
    # ç”¨å‰ä¸€å¤©çš„æ”¶ç›˜ä»·ï¼Œè¡¥å…¨æ”¶ç›˜ä»·çš„ç©ºå€¼
    close = df["æ”¶ç›˜ä»·"].ffill()
    # ç”¨æ”¶ç›˜ä»·è¡¥å…¨å¼€ç›˜ä»·ã€æœ€é«˜ä»·ã€æœ€ä½ä»·çš„ç©ºå€¼
    df = df.assign(
        æ”¶ç›˜ä»·=close,
        å¼€ç›˜ä»·=df["å¼€ç›˜ä»·"].fillna(value=close),
        æœ€é«˜ä»·=df["æœ€é«˜ä»·"].fillna(value=close),
        æœ€ä½ä»·=df["æœ€ä½ä»·"].fillna(value=close),
        å‡ä»·=df["å‡ä»·"].fillna(value=close),
        # è¡¥å…¨å‰æ”¶ç›˜ä»·
        å‰æ”¶ç›˜ä»·=df["å‰æ”¶ç›˜ä»·"].fillna(value=close.shift()),
    )

    # å¦‚æœå‰é¢ç®—è¿‡å¤æƒï¼Œå¤æƒä»·ä¹Ÿåšfillna
    if "æ”¶ç›˜ä»·_å¤æƒ" in df.columns:
        fq_cols = dict()
        fq_cols["æ”¶ç›˜ä»·_å¤æƒ"] = df["æ”¶ç›˜ä»·_å¤æƒ"].ffill()
        for col in ["å¼€ç›˜ä»·_å¤æƒ", "æœ€é«˜ä»·_å¤æƒ", "æœ€ä½ä»·_å¤æƒ"]:
            if col in df.columns:
                fq_cols[col] = df[col].fillna(value=fq_cols["æ”¶ç›˜ä»·_å¤æƒ"])
        df = df.assign(**fq_cols)

    # å°†åœç›˜æ—¶é—´çš„æŸäº›åˆ—ï¼Œæ•°æ®å¡«è¡¥ä¸º0
    fill_0_list = list(set(["æˆäº¤é‡", "æˆäº¤é¢", "æ¶¨è·Œå¹…"] + fill_0_list))
    df.loc[:, fill_0_list] = df[fill_0_list].fillna(value=0)

    # é’ˆå¯¹ç‰¹æ®Šçš„å­—æ®µéœ€è¦åšç‰¹æ®Šç©ºå€¼å¡«å……å¤„ç†
    # å¡«å……ç©ºå€¼
    for col in [
        "æ•£æˆ·èµ„é‡‘ä¹°å…¥é¢",
        "ä¸­æˆ·èµ„é‡‘ä¹°å…¥é¢",
        "å¤§æˆ·èµ„é‡‘ä¹°å…¥é¢",
        "æœºæ„èµ„é‡‘ä¹°å…¥é¢",
        "æ•£æˆ·èµ„é‡‘å–å‡ºé¢",
        "ä¸­æˆ·èµ„é‡‘å–å‡ºé¢",
        "å¤§æˆ·èµ„é‡‘å–å‡ºé¢",
        "æœºæ„èµ„é‡‘å–å‡ºé¢",
    ]:
        if col in df.columns:
            df.loc[:, col] = df[col].fillna(value=0)
    # å¡«å……Nå€¼
    for col in ["ä¸Šè¯50æˆåˆ†è‚¡", "æ²ªæ·±300æˆåˆ†è‚¡", "ä¸­è¯500æˆåˆ†è‚¡", "ä¸­è¯1000æˆåˆ†è‚¡", "ä¸­è¯2000æˆåˆ†è‚¡", "åˆ›ä¸šæ¿æŒ‡æˆåˆ†è‚¡"]:
        if col in df.columns:
            df.loc[:, col] = df[col].fillna(value="N")

    # ç”¨å‰ä¸€å¤©çš„æ•°æ®ï¼Œè¡¥å…¨å…¶ä½™ç©ºå€¼
    df.ffill(inplace=True)

    # å»é™¤ä¸Šå¸‚ä¹‹å‰çš„æ•°æ®
    df = df[df["è‚¡ç¥¨ä»£ç "].notnull()]

    # åˆ¤æ–­è®¡ç®—å½“å¤©æ˜¯å¦äº¤æ˜“
    df["æ˜¯å¦äº¤æ˜“"] = np.int8(1)
    df.loc[df["_merge"] == "right_only", "æ˜¯å¦äº¤æ˜“"] = np.int8(0)
    del df["_merge"]
    df.reset_index(drop=True, inplace=True)

    return df


def cal_zdt_price(df):
    """
    è®¡ç®—è‚¡ç¥¨å½“å¤©çš„æ¶¨è·Œåœä»·æ ¼ã€‚åœ¨è®¡ç®—æ¶¨è·Œåœä»·æ ¼çš„æ—¶å€™ï¼ŒæŒ‰ç…§ä¸¥æ ¼çš„å››èˆäº”å…¥ã€‚
    åŒ…å«STè‚¡ï¼Œä½†æ˜¯ä¸åŒ…å«æ–°è‚¡ã€‚

    æ¶¨è·Œåœåˆ¶åº¦è§„åˆ™:
        ---2020å¹´8æœˆ23æ—¥
        éSTè‚¡ç¥¨ 10%
        STè‚¡ç¥¨ 5%

        ---2020å¹´8æœˆ24æ—¥è‡³ä»Š
        æ™®é€šéSTè‚¡ç¥¨ 10%
        æ™®é€šSTè‚¡ç¥¨ 5%

        ç§‘åˆ›æ¿ï¼ˆsh68ï¼‰ 20%ï¼ˆä¸€ç›´æ˜¯20%ï¼Œä¸å—æ—¶é—´é™åˆ¶ï¼‰
        åˆ›ä¸šæ¿ï¼ˆsz3ï¼‰ 20%
        ç§‘åˆ›æ¿å’Œåˆ›ä¸šæ¿å³ä½¿STï¼Œæ¶¨è·Œå¹…é™åˆ¶ä¹Ÿæ˜¯20%

        åŒ—äº¤æ‰€ï¼ˆbjï¼‰ 30%

    å‚æ•°:
    df (DataFrame): å¿…é¡»å¾—æ˜¯æ—¥çº¿æ•°æ®ã€‚å¿…é¡»åŒ…å«çš„å­—æ®µï¼šå‰æ”¶ç›˜ä»·ï¼Œå¼€ç›˜ä»·ï¼Œæœ€é«˜ä»·ï¼Œæœ€ä½ä»·

    è¿”å›:
    DataFrame: åŒ…å«æ¶¨åœä»·ã€è·Œåœä»·ã€ä¸€å­—æ¶¨åœã€ä¸€å­—è·Œåœã€å¼€ç›˜æ¶¨åœã€å¼€ç›˜è·Œåœç­‰å­—æ®µçš„DataFrame
    """
    from decimal import Decimal, ROUND_HALF_UP, ROUND_DOWN

    # è®¡ç®—æ™®é€šè‚¡ç¥¨çš„æ¶¨åœä»·å’Œè·Œåœä»·
    cond = df["è‚¡ç¥¨åç§°"].str.contains("ST")
    df["æ¶¨åœä»·"] = df["å‰æ”¶ç›˜ä»·"] * 1.1
    df["è·Œåœä»·"] = df["å‰æ”¶ç›˜ä»·"] * 0.9
    df.loc[cond, "æ¶¨åœä»·"] = df["å‰æ”¶ç›˜ä»·"] * 1.05
    df.loc[cond, "è·Œåœä»·"] = df["å‰æ”¶ç›˜ä»·"] * 0.95

    # è®¡ç®—ç§‘åˆ›æ¿å’Œæ–°è§„åçš„åˆ›ä¸šæ¿çš„æ¶¨åœä»·å’Œè·Œåœä»·
    rule_kcb = df["è‚¡ç¥¨ä»£ç "].str.contains("sh68")  # ç§‘åˆ›æ¿
    new_rule_cyb = (df["äº¤æ˜“æ—¥æœŸ"] > pd.to_datetime("2020-08-23")) & df["è‚¡ç¥¨ä»£ç "].str.contains(
        "sz3"
    )  # æ–°è§„åçš„åˆ›ä¸šæ¿
    df.loc[rule_kcb | new_rule_cyb, "æ¶¨åœä»·"] = df["å‰æ”¶ç›˜ä»·"] * 1.2
    df.loc[rule_kcb | new_rule_cyb, "è·Œåœä»·"] = df["å‰æ”¶ç›˜ä»·"] * 0.8

    # è®¡ç®—åŒ—äº¤æ‰€çš„æ¶¨åœä»·å’Œè·Œåœä»·
    cond_bj = df["è‚¡ç¥¨ä»£ç "].str.contains("bj")
    df.loc[cond_bj, "æ¶¨åœä»·"] = df["å‰æ”¶ç›˜ä»·"] * 1.3
    df.loc[cond_bj, "è·Œåœä»·"] = df["å‰æ”¶ç›˜ä»·"] * 0.7

    # æ„Ÿè°¢éƒ­æ¯…è€æ¿æä¾›çš„ä»£ç ï¼Œhttps://bbs.quantclass.cn/thread/55667
    def price_round(number: float, *, ndigits: int = 2, rounding: str = ROUND_HALF_UP) -> float:
        """å¯¹ä»·æ ¼è¿›è¡Œå‡‘æ•´å¤„ç†

        åŒ—äº¤æ‰€è§„å®šâ€œè¶…è¿‡æ¶¨è·Œå¹…é™åˆ¶çš„ç”³æŠ¥ä¸ºæ— æ•ˆç”³æŠ¥â€ï¼Œå› æ­¤éœ€è¦å¯¹æ¶¨è·Œåœä»·é‡‡å–æˆªæ–­æ“ä½œï¼Œ
        å…¶ä½™å¸‚åœºçš„æ¶¨è·Œåœä»·åŠå¸¸è§„ä»·æ ¼å‡é‡‡å–å››èˆäº”å…¥æ–¹å¼å‡‘æ•´ã€‚

        Args:
            number (float): ä»·æ ¼ï¼ˆéè´Ÿæ•°ï¼‰
            ndigits (int, optional): ä»·æ ¼ç²¾åº¦ï¼ˆéè´Ÿæ•°ï¼‰ï¼Œé»˜è®¤ä¸º2
            rounding (str, optional): å‡‘æ•´æ–¹å¼ï¼Œæ”¯æŒå¦‚ä¸‹ï¼š
                ROUND_HALF_UP - é»˜è®¤ï¼Œå››èˆäº”å…¥
                ROUND_UP - å‘ä¸Šå–æ•´ï¼Œç”¨äºåŒ—äº¤æ‰€è·Œåœä»·è®¡ç®—
                ROUND_DOWN - å‘ä¸‹å–æ•´ï¼Œç”¨äºåŒ—äº¤æ‰€æ¶¨åœä»·è®¡ç®—

        Returns:
            float: å‡‘æ•´åçš„ç»“æœ
        """
        return float(
            Decimal(number + (-1e-7 if rounding == ROUND_UP else 1e-7)).quantize(
                Decimal(f"0.{'0' * ndigits}"), rounding
            )
        )

    # æ¶¨è·Œåœä»·æ ¼å‡‘æ•´ï¼ŒåŒ—äº¤æ‰€æˆªæ–­ï¼Œå…¶ä»–å¸‚åœºå››èˆäº”å…¥
    df["æ¶¨åœä»·"] = np.where(
        cond_bj, df["æ¶¨åœä»·"].apply(lambda x: price_round(x, rounding=ROUND_DOWN)), df["æ¶¨åœä»·"].apply(price_round)
    )
    df["è·Œåœä»·"] = np.where(
        cond_bj, df["è·Œåœä»·"].apply(lambda x: price_round(x, rounding=ROUND_UP)), df["è·Œåœä»·"].apply(price_round)
    )

    # åˆ¤æ–­æ˜¯å¦ä¸€å­—æ¶¨åœ
    df["ä¸€å­—æ¶¨åœ"] = False
    df.loc[df["æœ€ä½ä»·"] >= df["æ¶¨åœä»·"], "ä¸€å­—æ¶¨åœ"] = True

    # åˆ¤æ–­æ˜¯å¦ä¸€å­—è·Œåœ
    df["ä¸€å­—è·Œåœ"] = False
    df.loc[df["æœ€é«˜ä»·"] <= df["è·Œåœä»·"], "ä¸€å­—è·Œåœ"] = True

    # åˆ¤æ–­æ˜¯å¦å¼€ç›˜æ¶¨åœ
    df["å¼€ç›˜æ¶¨åœ"] = False
    df.loc[df["å¼€ç›˜ä»·"] >= df["æ¶¨åœä»·"], "å¼€ç›˜æ¶¨åœ"] = True

    # åˆ¤æ–­æ˜¯å¦å¼€ç›˜è·Œåœ
    df["å¼€ç›˜è·Œåœ"] = False
    df.loc[df["å¼€ç›˜ä»·"] <= df["è·Œåœä»·"], "å¼€ç›˜è·Œåœ"] = True

    return df


def get_most_stock_by_year(select_df, top_n=10):
    """
    è·å–æ¯å¹´ä¹°å…¥æœ€å¤šçš„è‚¡ç¥¨
    :param select_df:
    :param top_n:
    :return:
    """
    # æ–°å¢ï¼šè·å–æ‰€æœ‰è‚¡ç¥¨æœ€æ–°çš„åå­—
    last_stock_name = pd.DataFrame(select_df.groupby("è‚¡ç¥¨ä»£ç ", observed=True)["è‚¡ç¥¨åç§°"].last()).reset_index()
    # æ¯å¹´é€‰è‚¡æ¬¡æ•°nçš„è‚¡ç¥¨
    select_df["å¹´ä»½"] = select_df["é€‰è‚¡æ—¥æœŸ"].dt.year
    # æ¯å¹´çš„æ¬¡æ•°
    year_count = (
        pd.DataFrame(select_df.groupby(["å¹´ä»½", "è‚¡ç¥¨ä»£ç "], observed=True)["è‚¡ç¥¨ä»£ç "].count())
        .rename(columns={"è‚¡ç¥¨ä»£ç ": "é€‰ä¸­æ¬¡æ•°"})
        .reset_index()
    )
    # åˆå¹¶è‚¡ç¥¨åç§°
    year_count = year_count.merge(last_stock_name, on="è‚¡ç¥¨ä»£ç ", how="left")
    # è®¡ç®—é€‰ä¸­æ¬¡æ•°æ’å
    year_count["é€‰ä¸­æ¬¡æ•°_æ’å"] = year_count.groupby("å¹´ä»½", observed=True)["é€‰ä¸­æ¬¡æ•°"].rank(
        method="min", ascending=False
    )
    year_count = year_count[year_count["é€‰ä¸­æ¬¡æ•°_æ’å"] <= top_n]
    year_count = year_count[year_count["é€‰ä¸­æ¬¡æ•°"] > 0]
    # æ¯å¹´é€‰æ‹©æ’åé å‰çš„è‚¡ç¥¨
    groups = year_count.groupby("å¹´ä»½")
    years = pd.DataFrame()
    for t, g in groups:
        inx = 0 if pd.isnull(years.index.max()) else years.index.max() + 1
        years.loc[inx, "å¹´ä»½"] = str(int(t))
        g = g.sort_values(by="é€‰ä¸­æ¬¡æ•°_æ’å").reset_index()
        g["å†å¹´é€‰è‚¡æœ€å¤š"] = g["è‚¡ç¥¨åç§°"].astype(str) + "_" + g["é€‰ä¸­æ¬¡æ•°"].astype(str) + " "
        txt = g["å†å¹´é€‰è‚¡æœ€å¤š"].sum()
        years.loc[inx, "å†å¹´é€‰è‚¡æœ€å¤š"] = txt
    return years


PERIOD_OFFSET_URL = "https://api.quantclass.cn/api/data/client/real-trading/period-offset"


def download_period_offset(period_offset_file: Path):
    url = f"{PERIOD_OFFSET_URL}?t={int(time.time())}"
    for _ in range(5):
        try:
            logger.info(f"å‡†å¤‡ä¸‹è½½æ–‡ä»¶...")
            with requests.get(url, stream=True) as r:
                r.raise_for_status()  # å¦‚æœè¯·æ±‚å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                with open(period_offset_file, "wb") as f:
                    for chunk in r.iter_content(chunk_size=8192):
                        # å¦‚æœä½ é‡åˆ°äº†è®¤è¯é—®é¢˜ï¼Œè¯·å‚è€ƒrequestsæ–‡æ¡£ä¸­çš„è§£å†³æ–¹æ¡ˆ
                        f.write(chunk)
            logger.ok(f"ä¸‹è½½æˆåŠŸï¼Œæ–‡ä»¶è·¯å¾„æ˜¯ï¼š{period_offset_file}")
            break
        except Exception as e:
            logger.debug(e)
            logger.error(f"ä¸‹è½½å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯æ˜¯ï¼š{traceback.format_exc()}")
    else:
        raise Exception(f"ä¸‹è½½å¤±è´¥ï¼š{url}")


def hash_file(period_offset_file: Path):
    hash_func = hashlib.md5()
    with open(period_offset_file, "rb") as f:
        while chunk := f.read(8192):
            hash_func.update(chunk)
    return hash_func.hexdigest()


def check_period_offset(period_offset_file: Path):
    ts_path = period_offset_file.with_suffix(".ts")
    if ts_path.exists():
        if (time.time() - float(ts_path.read_text())) < 3600 * 24 * 19:  # æœ€å¤š19å¤©æ£€æŸ¥ä¸€æ¬¡
            return
    hash_value = hash_file(period_offset_file)
    url = f"{PERIOD_OFFSET_URL}"
    for _ in range(5):
        try:
            response = requests.get(url, params={"hash": hash_value, "time": int(time.time() * 1000)}, timeout=10)
            response.raise_for_status()  # å¦‚æœè¯·æ±‚å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
            if response.text == "False":
                logger.warning("å½“å‰äº¤æ˜“æ—¥å†å·²ä¸æ˜¯æœ€æ–°æ•°æ®ï¼Œéœ€è¦ä¸‹è½½")
                download_period_offset(period_offset_file)
            else:
                logger.ok("å½“å‰äº¤æ˜“æ—¥å†å·²æ˜¯æœ€æ–°æ•°æ®ã€‚")
            break
        except Exception as e:
            logger.debug(e)
            logger.error(f"æ ¡éªŒæ•°æ®ï¼Œé”™è¯¯ä¿¡æ¯æ˜¯ï¼š{traceback.format_exc()}")
    else:
        raise Exception(f"æ ¡éªŒæ•°æ®å¤±è´¥ï¼š{url}")

    # å†™å…¥æ—¶é—´æˆ³
    ts_path.write_text(f"{time.time()}")


def _factors_linear_regression(data, factor, neutralize_list, industry=None):
    """
    ä½¿ç”¨çº¿æ€§å›å½’å¯¹ç›®æ ‡å› å­è¿›è¡Œä¸­æ€§åŒ–å¤„ç†ï¼Œæ­¤æ–¹æ³•å¤–éƒ¨ä¸å¯ç›´æ¥è°ƒç”¨ã€‚
    :param data: è‚¡ç¥¨æ•°æ®
    :param factor: ç›®æ ‡å› å­
    :param neutralize_list:ä¸­æ€§åŒ–å¤„ç†å˜é‡list
    :param industry: è¡Œä¸šå­—æ®µåç§°ï¼Œé»˜è®¤ä¸ºNone
    :return: ä¸­æ€§åŒ–ä¹‹åçš„æ•°æ®
    """

    train_col = []
    train_col += neutralize_list

    lrm = LinearRegression(fit_intercept=True)  # åˆ›å»ºçº¿æ€§å›å½’æ¨¡å‹
    if industry:  # å¦‚æœéœ€è¦å¯¹è¡Œä¸šè¿›è¡Œä¸­æ€§åŒ–ï¼Œå°†è¡Œä¸šçš„åˆ—ååŠ å…¥åˆ°neutralize_listä¸­
        # è·å–ä¸€ä¸‹å½“å‘¨æœŸæœ‰ä»€ä¹ˆè¡Œä¸šï¼Œç”³ä¸‡ä¸€çº§è¡Œä¸šå‘ç”Ÿè¿‡æ‹†åˆ†ï¼Œæ‰€ä»¥éœ€è¦è€ƒè™‘
        ind_list = list(data[industry].unique())
        ind_list = ["æ‰€å±è¡Œä¸š_" + ind for ind in ind_list]

        industry_cols = [col for col in data.columns if "æ‰€å±è¡Œä¸š" in col]
        for col in industry_cols:
            if col not in train_col:
                if col in ind_list:
                    train_col.append(col)
    train = data[train_col].copy()  # è¾“å…¥å˜é‡
    label = data[[factor]].copy()  # é¢„æµ‹å˜é‡
    lrm.fit(train, label)  # çº¿æ€§æ‹Ÿåˆ
    predict = lrm.predict(train)  # è¾“å…¥å˜é‡è¿›è¡Œé¢„æµ‹
    data[factor + "_ä¸­æ€§"] = label.values - predict  # è®¡ç®—æ®‹å·®
    return data


def factor_neutralization(data, factor, neutralize_list, industry=None):
    """
    ä½¿ç”¨çº¿æ€§å›å½’å¯¹ç›®æ ‡å› å­è¿›è¡Œä¸­æ€§åŒ–å¤„ç†ï¼Œæ­¤æ–¹æ³•å¯ä»¥è¢«å¤–éƒ¨è°ƒç”¨ã€‚
    :param data: è‚¡ç¥¨æ•°æ®
    :param factor: ç›®æ ‡å› å­
    :param neutralize_list:ä¸­æ€§åŒ–å¤„ç†å˜é‡list
    :param industry: è¡Œä¸šå­—æ®µåç§°ï¼Œé»˜è®¤ä¸ºNone
    :return: ä¸­æ€§åŒ–ä¹‹åçš„æ•°æ®
    """
    # å°†éœ€è¦ç”¨åˆ°çš„æ•°æ®copyä¸€ä»½
    copy_cols = ["äº¤æ˜“æ—¥æœŸ", "è‚¡ç¥¨ä»£ç ", factor] + neutralize_list
    if industry:
        copy_cols.append(industry)
    df = data[copy_cols].copy()
    # åˆ é™¤æ•°æ®ä¸­çš„æ— ç©·å¤§ä»¥åŠç©ºå€¼
    df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=copy_cols, how="any")
    # æœéœ€è¦å¯¹è¡Œä¸šè¿›è¡Œä¸­æ€§åŒ–ï¼Œå…ˆæ„å»ºè¡Œä¸šå“‘å˜é‡
    if industry:
        # å¯¹è¡Œä¸šè¿›è¡Œå“‘å˜é‡å¤„ç†
        ind = df[industry]
        ind = pd.get_dummies(
            ind, columns=[industry], prefix="æ‰€å±è¡Œä¸š", prefix_sep="_", dummy_na=False, drop_first=False
        )
        """
        drop_first=Trueä¼šå¯¼è‡´æŸä¸€è¡Œä¸šçš„çš„å“‘å˜é‡è¢«åˆ é™¤ï¼Œè¿™æ ·çš„åšçš„ç›®çš„æ˜¯ä¸ºäº†æ¶ˆé™¤è¡Œä¸šé—´çš„å¤šé‡å…±çº¿æ€§
        è¯¦è§ï¼šhttps://www.learndatasci.com/glossary/dummy-variable-trap/

        2023å¹´6æœˆ25æ—¥èµ·
        ä¸å†ä½¿ç”¨drop_first=Trueï¼Œè€ŒæŒ‡å®šä¸€ä¸ªè¡Œä¸šç›´æ¥åˆ é™¤ï¼Œé¿å…ä¸åŒçš„å‘¨æœŸåˆ é™¤ä¸åŒçš„è¡Œä¸šã€‚
        """
        # åˆ é™¤ä¸€ä¸ªè¡Œä¸šï¼ŒåŸå› å¦‚ä¸Šæåˆ°çš„drop_first
        ind.drop(columns=["æ‰€å±è¡Œä¸š_ç»¼åˆ"], inplace=True)
    else:
        ind = pd.DataFrame()
    df = pd.concat([df, ind], axis=1, copy=False)
    # ä¸­æ€§åŒ–
    df = df.groupby(["äº¤æ˜“æ—¥æœŸ"], group_keys=False).apply(
        _factors_linear_regression, factor=factor, neutralize_list=neutralize_list, industry=industry
    )

    # å°†è®¡ç®—å¥½çš„æ•°æ®åˆå¹¶åˆ°åŸå§‹æ•°æ®ä¸Š
    data = pd.merge(data, df[["äº¤æ˜“æ—¥æœŸ", "è‚¡ç¥¨ä»£ç ", factor + "_ä¸­æ€§"]], "left", ["äº¤æ˜“æ—¥æœŸ", "è‚¡ç¥¨ä»£ç "])

    return data
